{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Project - Phase 2 (Destination Suggestion)\n",
    "<div style=\"text-align: center\">\n",
    "<h1 style = \"color: red\"> Sharif University Of Technology</h1>\n",
    "<h2 style = \"color: green\"> DR. Mahdieh Soleymani | DR. MohammadHossein Rohban </h2>\n",
    "<h3 style = \"color: cyan\"> Head of Project: AmirHossein Razlighi <h3>\n",
    "<h3 style = \"color: cyan\"> Designed By: AmirHossein Razlighi, Javad Hezareh, Payam Taebi, Alireza Sakhaei, Ali Banayeean, Yalda Shabanzadeh, Hamidreza Yaghoubi, Alireza Heidari <h3>\n",
    "<h4 style = \"color: white\"> Ask your questions via quera</h4>\n",
    "<h5> Save your file with format: STUDENT NUMBER_Phase2.ipynb or .zip </h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "<img src=\"./Images/Uber_research.jpg\" width=\"100%\" height=\"auto\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are a research engineer at Uber and you are asked to design a system that suggests destinations to the passengers. The system should be able to suggest destinations based on the passenger's history. For example, one passenger may save a variety of locations (like home, work, gym, etc.). This passenger may go to gym, often on weekends and when he/she requests a car from Home. \n",
    "\n",
    "So, for example, if I am a student, going to university usually from Saturday to Wednesday on 8:00 from \"home\", the next time I request a car from \"home\" on 8:00, the system should suggest \"university\" as the destination. Now, it's not that simple always, so we should seek for smart wayys to solve this problem!\n",
    "\n",
    "As you may understood by now, we should engineer some of features from the data we have and try to predict the next destination of the passenger.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "random.seed(2024)\n",
    "np.random.seed(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach: Using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you should prepare the data for KNN. You should load the dataset file that we provided, named `Data/output.json` and then clean it, do all the required preprocessings and then split into train-test-val sets if necessary. Note that we provided a splitted test set for you, named `Data/output_test.json`. You should not use this file for training or validation. You should only use it for testing your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin lat</th>\n",
       "      <th>origin lon</th>\n",
       "      <th>dest lat</th>\n",
       "      <th>dest lon</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>36.000</td>\n",
       "      <td>51.085</td>\n",
       "      <td>2024-01-31 13:07:00</td>\n",
       "      <td>2024-01-31 14:43:00</td>\n",
       "      <td>43.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000</td>\n",
       "      <td>51.085</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>2024-01-31 15:13:00</td>\n",
       "      <td>2024-01-31 16:49:00</td>\n",
       "      <td>36.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>35.745</td>\n",
       "      <td>51.465</td>\n",
       "      <td>2024-01-31 20:41:00</td>\n",
       "      <td>2024-01-31 20:54:00</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.745</td>\n",
       "      <td>51.465</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>2024-01-31 21:24:00</td>\n",
       "      <td>2024-01-31 21:37:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>2024-01-31 23:38:00</td>\n",
       "      <td>2024-01-31 23:58:00</td>\n",
       "      <td>19.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day  origin lat  origin lon  dest lat  dest lon  \\\n",
       "0        0    0      35.625      51.375    36.000    51.085   \n",
       "1        0    0      36.000      51.085    35.625    51.375   \n",
       "2        0    0      35.680      51.445    35.745    51.465   \n",
       "3        0    0      35.745      51.465    35.680    51.445   \n",
       "4        0    1      35.625      51.375    35.680    51.445   \n",
       "\n",
       "           start_time            end_time  price  \n",
       "0 2024-01-31 13:07:00 2024-01-31 14:43:00  43.99  \n",
       "1 2024-01-31 15:13:00 2024-01-31 16:49:00  36.66  \n",
       "2 2024-01-31 20:41:00 2024-01-31 20:54:00  15.08  \n",
       "3 2024-01-31 21:24:00 2024-01-31 21:37:00  10.00  \n",
       "4 2024-01-31 23:38:00 2024-01-31 23:58:00  19.48  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset for training\n",
    "data = pd.read_json('Data/output.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin lat</th>\n",
       "      <th>origin lon</th>\n",
       "      <th>dest lat</th>\n",
       "      <th>dest lon</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.225</td>\n",
       "      <td>35.640</td>\n",
       "      <td>51.270</td>\n",
       "      <td>2024-01-31 11:58:00</td>\n",
       "      <td>2024-01-31 12:12:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.250</td>\n",
       "      <td>35.690</td>\n",
       "      <td>51.295</td>\n",
       "      <td>2024-01-31 21:58:00</td>\n",
       "      <td>2024-01-31 22:18:00</td>\n",
       "      <td>11.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.225</td>\n",
       "      <td>35.865</td>\n",
       "      <td>51.045</td>\n",
       "      <td>2024-01-31 20:05:00</td>\n",
       "      <td>2024-01-31 20:58:00</td>\n",
       "      <td>23.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>35.875</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.890</td>\n",
       "      <td>51.315</td>\n",
       "      <td>2024-01-31 17:39:00</td>\n",
       "      <td>2024-01-31 18:17:00</td>\n",
       "      <td>13.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.385</td>\n",
       "      <td>2024-01-31 13:16:00</td>\n",
       "      <td>2024-01-31 13:19:00</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day  origin lat  origin lon  dest lat  dest lon  \\\n",
       "0       24    6      35.650      51.225    35.640    51.270   \n",
       "1       46    2      35.625      51.250    35.690    51.295   \n",
       "2       27    5      35.650      51.225    35.865    51.045   \n",
       "3        7    4      35.875      51.375    35.890    51.315   \n",
       "4       27    3      35.625      51.375    35.650    51.385   \n",
       "\n",
       "           start_time            end_time  price  \n",
       "0 2024-01-31 11:58:00 2024-01-31 12:12:00  10.00  \n",
       "1 2024-01-31 21:58:00 2024-01-31 22:18:00  11.84  \n",
       "2 2024-01-31 20:05:00 2024-01-31 20:58:00  23.36  \n",
       "3 2024-01-31 17:39:00 2024-01-31 18:17:00  13.74  \n",
       "4 2024-01-31 13:16:00 2024-01-31 13:19:00  15.08  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset for testing\n",
    "test_data = pd.read_json('Data/output_test.json')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users:     60\n",
      "Randomly selected user id:  30\n"
     ]
    }
   ],
   "source": [
    "# print out the number of unique users and also randomly select one user\n",
    "# TODO\n",
    "print('Number of unique users:    ', len(data['user_id'].unique()))\n",
    "print('Randomly selected user id: ', data['user_id'].unique()[random.randint(0, len(data['user_id'].unique()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "\n",
    "# Uncomment the following line if you are using Google Colab\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    }
   ],
   "source": [
    "# choose the data related to the randomly selected user\n",
    "# show destinations of this user on map\n",
    "# You should Use Kepler.gl to visualize the data\n",
    "\n",
    "# TODO\n",
    "user_id = data['user_id'].unique()[random.randint(0, len(data['user_id'].unique()))]\n",
    "user_data = data[data['user_id'] == user_id]\n",
    "map_1 = KeplerGl(height=400)\n",
    "map_1.add_data(data=user_data[['dest lat' , 'dest lon']], name='user_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ae7455e4e74c409516e3cd5b8fecca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'user_data': {'index': [3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample output:\n",
    "map_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you should do feature engineering stuff! Extract the features that you think are important. Split the features into training set and also extract the related outputs (used for our model further). These outputs may be strings (name of destination) or destination's latitude/longitude or etc. Use your creativity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing Training Data\n",
    "# Break down the start_time and end_time into hour, minute, and second\n",
    "data['start_time'] = pd.to_datetime(data['start_time'])\n",
    "data['end_time'] = pd.to_datetime(data['end_time'])\n",
    "data['start_hour'] = data['start_time'].dt.hour\n",
    "data['start_minute'] = data['start_time'].dt.minute\n",
    "data['start_second'] = data['start_time'].dt.second\n",
    "data['end_hour'] = data['end_time'].dt.hour\n",
    "data['end_minute'] = data['end_time'].dt.minute\n",
    "data['end_second'] = data['end_time'].dt.second\n",
    "data = data.drop(['start_time', 'end_time'], axis=1)\n",
    "# Make user_id one-hot encoded\n",
    "user_id = pd.get_dummies(data['user_id'])\n",
    "data = pd.concat([data, user_id], axis=1)\n",
    "data = data.drop(['user_id'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing Test Data\n",
    "# Break down the start_time and end_time into hour, minute, and second\n",
    "test_data['start_time'] = pd.to_datetime(test_data['start_time'])\n",
    "test_data['end_time'] = pd.to_datetime(test_data['end_time'])\n",
    "test_data['start_hour'] = test_data['start_time'].dt.hour\n",
    "test_data['start_minute'] = test_data['start_time'].dt.minute\n",
    "test_data['start_second'] = test_data['start_time'].dt.second\n",
    "test_data['end_hour'] = test_data['end_time'].dt.hour\n",
    "test_data['end_minute'] = test_data['end_time'].dt.minute\n",
    "test_data['end_second'] = test_data['end_time'].dt.second\n",
    "test_data = test_data.drop(['start_time', 'end_time'], axis=1)\n",
    "# Make user_id one-hot encoded\n",
    "user_id = pd.get_dummies(test_data['user_id'])\n",
    "test_data = pd.concat([test_data, user_id], axis=1)\n",
    "test_data = test_data.drop(['user_id'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Spliting the data into input and output\n",
    "x_train = data.drop(['dest lat', 'dest lon'], axis=1)\n",
    "y_train = data[['dest lat', 'dest lon']]\n",
    "x_test = test_data.drop(['dest lat', 'dest lon'], axis=1)\n",
    "y_test = test_data[['dest lat', 'dest lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>origin lat</th>\n",
       "      <th>origin lon</th>\n",
       "      <th>price</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_minute</th>\n",
       "      <th>start_second</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>end_minute</th>\n",
       "      <th>end_second</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>43.99</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>36.000</td>\n",
       "      <td>51.085</td>\n",
       "      <td>36.66</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>15.08</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35.745</td>\n",
       "      <td>51.465</td>\n",
       "      <td>10.00</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>19.48</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day  origin lat  origin lon  price  start_hour  start_minute  start_second  \\\n",
       "0    0      35.625      51.375  43.99          13             7             0   \n",
       "1    0      36.000      51.085  36.66          15            13             0   \n",
       "2    0      35.680      51.445  15.08          20            41             0   \n",
       "3    0      35.745      51.465  10.00          21            24             0   \n",
       "4    1      35.625      51.375  19.48          23            38             0   \n",
       "\n",
       "   end_hour  end_minute  end_second  ...     50     51     52     53     54  \\\n",
       "0        14          43           0  ...  False  False  False  False  False   \n",
       "1        16          49           0  ...  False  False  False  False  False   \n",
       "2        20          54           0  ...  False  False  False  False  False   \n",
       "3        21          37           0  ...  False  False  False  False  False   \n",
       "4        23          58           0  ...  False  False  False  False  False   \n",
       "\n",
       "      55     56     57     58     59  \n",
       "0  False  False  False  False  False  \n",
       "1  False  False  False  False  False  \n",
       "2  False  False  False  False  False  \n",
       "3  False  False  False  False  False  \n",
       "4  False  False  False  False  False  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dest lat</th>\n",
       "      <th>dest lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.000</td>\n",
       "      <td>51.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.745</td>\n",
       "      <td>51.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dest lat  dest lon\n",
       "0    36.000    51.085\n",
       "1    35.625    51.375\n",
       "2    35.745    51.465\n",
       "3    35.680    51.445\n",
       "4    35.680    51.445"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:  (17994, 70)\n",
      "Shape of y_train:  (17994, 2)\n",
      "Shape of x_test:   (4499, 70)\n",
      "Shape of y_test:   (4499, 2)\n"
     ]
    }
   ],
   "source": [
    "# print out the shape of the train and test dataframes\n",
    "# TODO\n",
    "print('Shape of x_train: ', x_train.shape)\n",
    "print('Shape of y_train: ', y_train.shape)\n",
    "print('Shape of x_test:  ', x_test.shape)\n",
    "print('Shape of y_test:  ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize_dataframe(df):\n",
    "    scaler = MinMaxScaler()\n",
    "    df_normalized = df.copy()\n",
    "    for column in df.columns:\n",
    "        df_normalized[column] = scaler.fit_transform(df[column].values.reshape(-1, 1))\n",
    "\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the train and test dataframes\n",
    "x_train_normalized = normalize_dataframe(x_train)\n",
    "x_test_normalized = normalize_dataframe(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to implement our KNN model. For further information on how KNN works, please refer to [this](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) link. As you can see, it's a simple algorithm. We will start with this and see the results of our _destination suggestion_ system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the model\n",
    "# # TODO: You can change the signature of functions and also add any function you need\n",
    "\n",
    "class NearestNeighbor():\n",
    "    def __init__(self):\n",
    "        self.train_X = None\n",
    "        self.train_y = None\n",
    "        self.dest_lat_dict = {}\n",
    "        self.dest_lon_dict = {}\n",
    "\n",
    "    def fit(self, train_X, train_y):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "        for i in range(len(train_y)):\n",
    "            if train_y.iloc[i]['dest lat'] not in self.dest_lat_dict:\n",
    "                self.dest_lat_dict[train_y.iloc[i]['dest lat']] = 0\n",
    "            if train_y.iloc[i]['dest lon'] not in self.dest_lon_dict:\n",
    "                self.dest_lon_dict[train_y.iloc[i]['dest lon']] = 0\n",
    "\n",
    "    def predict(self, x: pd.DataFrame, k):\n",
    "        predictions = []\n",
    "        x = np.array(x)\n",
    "\n",
    "        for row in x:\n",
    "            distances = np.linalg.norm(self.train_X - row, axis=1)\n",
    "            nearest_neighbor_indices = np.argsort(distances)[:k]\n",
    "            \n",
    "            epsilon = 0.00001\n",
    "            for index, i in enumerate(nearest_neighbor_indices):\n",
    "                self.dest_lat_dict[self.train_y.iloc[i]['dest lat']] += 1 + (epsilon/(index + 1))\n",
    "                self.dest_lon_dict[self.train_y.iloc[i]['dest lon']] += 1 + (epsilon/(index + 1))\n",
    "\n",
    "            prediction_lat = max(self.dest_lat_dict, key=self.dest_lat_dict.get)\n",
    "            prediction_lon = max(self.dest_lon_dict, key=self.dest_lon_dict.get)\n",
    "            \n",
    "            predictions.append([prediction_lat, prediction_lon])\n",
    "            \n",
    "            for key in self.dest_lat_dict:\n",
    "                self.dest_lat_dict[key] = 0\n",
    "            for key in self.dest_lon_dict:\n",
    "                self.dest_lon_dict[key] = 0\n",
    "            \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "# TODO\n",
    "model = NearestNeighbor()\n",
    "model.fit(x_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on training data\n",
    "# TODO\n",
    "predictions = model.predict(x_train_normalized, k=3)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  0.942591975102812\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean((predictions == np.array(y_train)) == np.array([True, True]))\n",
    "print('Accuracy on training data: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on test data\n",
    "# TODO\n",
    "predictions = model.predict(x_test_normalized, k=3)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.6086908201822627\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean((predictions == np.array(y_test)) == np.array([True, True]))\n",
    "print('Accuracy on test data: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use KNN for this problem? Why (or why not)? If the patterns in our datatset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "**Your Answer**: \n",
    "using KNN for predicting passenger destinations based on travel histories can be a reasonable choice, especially for relatively simple and locally smooth patterns. However, as the complexity of patterns increases, and the dataset becomes more complicated, other models might be more robust and provide better performance. Consideration should be given to the computational cost and the sensitivity of KNN to noise and outliers in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Approach: Using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we are going to use XGBoost to predict the next destination of the passenger. You can use `xgboost` library to implement this model. To learn more about XGBoost, please refer to [this](https://en.wikipedia.org/wiki/XGBoost) link. It should be familiar to you, as you saw decision trees in the class.\n",
    "\n",
    "For this part, you can use the same data (that you did all the processes on) from the previous part. Or, if you need, you can reload the dataset and do new preprocessings on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the overview of how XGBoost works in the image below:\n",
    "\n",
    "<dev style=\"text-align: center\">\n",
    "<img src=\"./Images/XGBoost.png\" />\n",
    "</dev>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, this is for more information and you **do not** need to implement `XGBoost` from scratch. You can use the library that we mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/sina/miniforge3/envs/ai/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /Users/sina/miniforge3/envs/ai/lib/python3.10/site-packages (from xgboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in /Users/sina/miniforge3/envs/ai/lib/python3.10/site-packages (from xgboost) (1.11.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Defining the model\n",
    "# TODO: You can change the signature of functions and also add any function you need\n",
    "class Encoder():\n",
    "    def __init__(self):\n",
    "        self.dest_lat_dict = None\n",
    "        self.dest_lon_dict = None\n",
    "        self.dest_lat_dict_inv = None\n",
    "        self.dest_lon_dict_inv = None\n",
    "        \n",
    "    def fit(self, y):\n",
    "        self.dest_lat_dict = {value: key for key, value in enumerate(y['dest lat'].unique())}\n",
    "        self.dest_lon_dict = {value: key for key, value in enumerate(y['dest lon'].unique())}\n",
    "        self.dest_lat_dict_inv = {key: value for key, value in enumerate(y['dest lat'].unique())}\n",
    "        self.dest_lon_dict_inv = {key: value for key, value in enumerate(y['dest lon'].unique())}\n",
    "\n",
    "    def transform(self, y):\n",
    "        y_new = y.copy()\n",
    "        y_new['dest lat'] = y_new['dest lat'].map(self.dest_lat_dict)\n",
    "        y_new['dest lon'] = y_new['dest lon'].map(self.dest_lon_dict)\n",
    "        return y_new\n",
    "        \n",
    "    def inverse_transform(self, enc):\n",
    "        enc_new = enc.copy()\n",
    "        enc_new['dest lat'] = enc_new['dest lat'].map(self.dest_lat_dict_inv)\n",
    "        enc_new['dest lon'] = enc_new['dest lon'].map(self.dest_lon_dict_inv)\n",
    "        return enc_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of dest lat in training data: 64\n",
      "Unique values of dest lon in training data: 65\n",
      "Unique values of dest lat in test data: 64\n",
      "Unique values of dest lon in test data: 65\n",
      "Unique values of dest lat in all data: 64\n",
      "Unique values of dest lon in all data: 65\n"
     ]
    }
   ],
   "source": [
    "print('Unique values of dest lat in training data:', len(y_train['dest lat'].unique()))\n",
    "print('Unique values of dest lon in training data:', len(y_train['dest lon'].unique()))\n",
    "print('Unique values of dest lat in test data:', len(y_test['dest lat'].unique()))\n",
    "print('Unique values of dest lon in test data:', len(y_test['dest lon'].unique()))\n",
    "print('Unique values of dest lat in all data:', len(data['dest lat'].unique()))\n",
    "print('Unique values of dest lon in all data:', len(data['dest lon'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fit the Encoder on training data\n",
    "encoder = Encoder()\n",
    "encoder.fit(y_train)\n",
    "y_train_encoded = encoder.transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: transform the training and test data\n",
    "# and fit the model on training data\n",
    "classifier1 = xgb.XGBClassifier(objective='multi:softmax', num_class=len(y_train['dest lat'].unique()))\n",
    "classifier2 = xgb.XGBClassifier(objective='multi:softmax', num_class=len(y_train['dest lon'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=64,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=64,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=64,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier1.fit(x_train, y_train_encoded['dest lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=65,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=65,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None, num_class=65,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2.fit(x_train, y_train_encoded['dest lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  0.9848838501722796\n"
     ]
    }
   ],
   "source": [
    "# TODO: print out train-data accuracy\n",
    "predicted_lats = classifier1.predict(x_train)\n",
    "predicted_lons = classifier2.predict(x_train)\n",
    "\n",
    "predictions = np.array([predicted_lats, predicted_lons]).T\n",
    "\n",
    "predictions = encoder.inverse_transform(pd.DataFrame(predictions, columns=['dest lat', 'dest lon']))\n",
    "\n",
    "accuracy = np.mean((predictions == np.array(y_train)) == np.array([True, True]))\n",
    "\n",
    "print('Accuracy on training data: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  0.6995999110913537\n"
     ]
    }
   ],
   "source": [
    "# TODO: print out test-data accuracy\n",
    "predicted_lats = classifier1.predict(x_test)\n",
    "predicted_lons = classifier2.predict(x_test)\n",
    "\n",
    "predictions = np.array([predicted_lats, predicted_lons]).T\n",
    "\n",
    "predictions = encoder.inverse_transform(pd.DataFrame(predictions, columns=['dest lat', 'dest lon']))\n",
    "\n",
    "accuracy = np.mean((predictions == np.array(y_test)) == np.array([True, True]))\n",
    "\n",
    "print('Accuracy on training data: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use XGBoost for this problem? Why (or why not)? If the patterns in our datatset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "**Your Answer**: In comparison to KNN, which may struggle with high-dimensional data and intricate patterns, XGBoost is often considered more robust in such scenarios. It can automatically adapt to complex structures without being as sensitive to the dimensionality of the data.\n",
    "\n",
    "XGBoost is known for its ability to handle complex patterns in the data, making it a strong candidate when dealing with intricate relationships in passengers' travel histories. Its ensemble nature, regularization techniques, and flexibility in capturing non-linear dependencies contribute to its robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Please explain the problem of overfitting in XGBoost. How can you solve it? Provide a brief explanation.\n",
    "\n",
    "**Your Answer**: Overfitting in XGBoost happens when the model learns noise in the training data, harming its ability to generalize to new data. To address overfitting:\n",
    "\n",
    "1. Use regularization parameters (L1 and L2).\n",
    "2. Adjust the learning rate to control the step size.\n",
    "3. Set limits on tree depth.\n",
    "4. Implement early stopping to halt training when performance on validation data plateaus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Approach: Classifier Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we are going to use a classifier using neural networks. You can think of this approach and how to model the problem as a classification problem in many ways! So, we are not going to restrict your creativity. Just a hint: You can consider each of the unique destinations (in whole dataset) as a class and then train a classifier to classify the destinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the data for our neural network. Again, you should extract required features from the dataset and then split the dataset into train-test-val sets if necessary. For your ease, we prepared another version of `output.json` that helps you to extract features for this part, easier. So, please load `Data/trip_data.json` and use it for training set and validation set. You should use `Data/trip_data_test.json` for testing your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, [35.625, 51.375]]</td>\n",
       "      <td>[restaurant, [36.0, 51.085]]</td>\n",
       "      <td>2024-01-31 13:07:00</td>\n",
       "      <td>2024-01-31 14:43:00</td>\n",
       "      <td>43.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[restaurant, [36.0, 51.085]]</td>\n",
       "      <td>[work, [35.625, 51.375]]</td>\n",
       "      <td>2024-01-31 15:13:00</td>\n",
       "      <td>2024-01-31 16:49:00</td>\n",
       "      <td>36.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[home, [35.68, 51.445]]</td>\n",
       "      <td>[restaurant, [35.745, 51.465]]</td>\n",
       "      <td>2024-01-31 20:41:00</td>\n",
       "      <td>2024-01-31 20:54:00</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[restaurant, [35.745, 51.465]]</td>\n",
       "      <td>[home, [35.68, 51.445]]</td>\n",
       "      <td>2024-01-31 21:24:00</td>\n",
       "      <td>2024-01-31 21:37:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[work, [35.625, 51.375]]</td>\n",
       "      <td>[home, [35.68, 51.445]]</td>\n",
       "      <td>2024-01-31 23:38:00</td>\n",
       "      <td>2024-01-31 23:58:00</td>\n",
       "      <td>19.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day                          origin  \\\n",
       "0        0    0        [work, [35.625, 51.375]]   \n",
       "1        0    0    [restaurant, [36.0, 51.085]]   \n",
       "2        0    0         [home, [35.68, 51.445]]   \n",
       "3        0    0  [restaurant, [35.745, 51.465]]   \n",
       "4        0    1        [work, [35.625, 51.375]]   \n",
       "\n",
       "                      destination          start_time            end_time  \\\n",
       "0    [restaurant, [36.0, 51.085]] 2024-01-31 13:07:00 2024-01-31 14:43:00   \n",
       "1        [work, [35.625, 51.375]] 2024-01-31 15:13:00 2024-01-31 16:49:00   \n",
       "2  [restaurant, [35.745, 51.465]] 2024-01-31 20:41:00 2024-01-31 20:54:00   \n",
       "3         [home, [35.68, 51.445]] 2024-01-31 21:24:00 2024-01-31 21:37:00   \n",
       "4         [home, [35.68, 51.445]] 2024-01-31 23:38:00 2024-01-31 23:58:00   \n",
       "\n",
       "   price  \n",
       "0  43.99  \n",
       "1  36.66  \n",
       "2  15.08  \n",
       "3  10.00  \n",
       "4  19.48  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training dataset\n",
    "# TODO\n",
    "data_raw = pd.read_json('Data/trip_data.json')\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>[pool, [35.65, 51.225]]</td>\n",
       "      <td>[home, [35.64, 51.27]]</td>\n",
       "      <td>2024-01-31 11:58:00</td>\n",
       "      <td>2024-01-31 12:12:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>[university, [35.625, 51.25]]</td>\n",
       "      <td>[restaurant, [35.69, 51.295]]</td>\n",
       "      <td>2024-01-31 21:58:00</td>\n",
       "      <td>2024-01-31 22:18:00</td>\n",
       "      <td>11.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>[pool, [35.65, 51.225]]</td>\n",
       "      <td>[restaurant, [35.865, 51.045]]</td>\n",
       "      <td>2024-01-31 20:05:00</td>\n",
       "      <td>2024-01-31 20:58:00</td>\n",
       "      <td>23.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>[work, [35.875, 51.375]]</td>\n",
       "      <td>[home, [35.89, 51.315]]</td>\n",
       "      <td>2024-01-31 17:39:00</td>\n",
       "      <td>2024-01-31 18:17:00</td>\n",
       "      <td>13.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>[work, [35.625, 51.375]]</td>\n",
       "      <td>[restaurant, [35.65, 51.385]]</td>\n",
       "      <td>2024-01-31 13:16:00</td>\n",
       "      <td>2024-01-31 13:19:00</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day                         origin  \\\n",
       "0       24    6        [pool, [35.65, 51.225]]   \n",
       "1       46    2  [university, [35.625, 51.25]]   \n",
       "2       27    5        [pool, [35.65, 51.225]]   \n",
       "3        7    4       [work, [35.875, 51.375]]   \n",
       "4       27    3       [work, [35.625, 51.375]]   \n",
       "\n",
       "                      destination          start_time            end_time  \\\n",
       "0          [home, [35.64, 51.27]] 2024-01-31 11:58:00 2024-01-31 12:12:00   \n",
       "1   [restaurant, [35.69, 51.295]] 2024-01-31 21:58:00 2024-01-31 22:18:00   \n",
       "2  [restaurant, [35.865, 51.045]] 2024-01-31 20:05:00 2024-01-31 20:58:00   \n",
       "3         [home, [35.89, 51.315]] 2024-01-31 17:39:00 2024-01-31 18:17:00   \n",
       "4   [restaurant, [35.65, 51.385]] 2024-01-31 13:16:00 2024-01-31 13:19:00   \n",
       "\n",
       "   price  \n",
       "0  10.00  \n",
       "1  11.84  \n",
       "2  23.36  \n",
       "3  13.74  \n",
       "4  15.08  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test dataset\n",
    "# TODO\n",
    "test_data_raw = pd.read_json('Data/trip_data_test.json')\n",
    "test_data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    df['origin_lat'] = df['origin'].apply(lambda x: x[1][0])\n",
    "    df['origin_long'] = df['origin'].apply(lambda x: x[1][1])\n",
    "    df['origin'] = df['origin'].apply(lambda x: x[0])\n",
    "\n",
    "    \n",
    "    df['dest_lat'] = df['destination'].apply(lambda x: x[1][0])\n",
    "    df['dest_long'] = df['destination'].apply(lambda x: x[1][1])\n",
    "    df['dest'] = df['destination'].apply(lambda x: x[0])\n",
    "\n",
    "    df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "    df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "    df['start_time'] = df['start_time'].dt.strftime('%H:%M:%S')\n",
    "    df['end_time'] = df['end_time'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "    df = df.drop(['destination'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_long</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_long</th>\n",
       "      <th>dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>work</td>\n",
       "      <td>13:07:00</td>\n",
       "      <td>14:43:00</td>\n",
       "      <td>43.99</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>36.000</td>\n",
       "      <td>51.085</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>15:13:00</td>\n",
       "      <td>16:49:00</td>\n",
       "      <td>36.66</td>\n",
       "      <td>36.000</td>\n",
       "      <td>51.085</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>home</td>\n",
       "      <td>20:41:00</td>\n",
       "      <td>20:54:00</td>\n",
       "      <td>15.08</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>35.745</td>\n",
       "      <td>51.465</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>21:24:00</td>\n",
       "      <td>21:37:00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>35.745</td>\n",
       "      <td>51.465</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>23:38:00</td>\n",
       "      <td>23:58:00</td>\n",
       "      <td>19.48</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day      origin start_time  end_time  price  origin_lat  \\\n",
       "0        0    0        work   13:07:00  14:43:00  43.99      35.625   \n",
       "1        0    0  restaurant   15:13:00  16:49:00  36.66      36.000   \n",
       "2        0    0        home   20:41:00  20:54:00  15.08      35.680   \n",
       "3        0    0  restaurant   21:24:00  21:37:00  10.00      35.745   \n",
       "4        0    1        work   23:38:00  23:58:00  19.48      35.625   \n",
       "\n",
       "   origin_long  dest_lat  dest_long        dest  \n",
       "0       51.375    36.000     51.085  restaurant  \n",
       "1       51.085    35.625     51.375        work  \n",
       "2       51.445    35.745     51.465  restaurant  \n",
       "3       51.465    35.680     51.445        home  \n",
       "4       51.375    35.680     51.445        home  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features and do preprocessing if needed\n",
    "# TODO\n",
    "data = extract_features(data_raw)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_long</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_long</th>\n",
       "      <th>dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>pool</td>\n",
       "      <td>11:58:00</td>\n",
       "      <td>12:12:00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.225</td>\n",
       "      <td>35.640</td>\n",
       "      <td>51.270</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>university</td>\n",
       "      <td>21:58:00</td>\n",
       "      <td>22:18:00</td>\n",
       "      <td>11.84</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.250</td>\n",
       "      <td>35.690</td>\n",
       "      <td>51.295</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>pool</td>\n",
       "      <td>20:05:00</td>\n",
       "      <td>20:58:00</td>\n",
       "      <td>23.36</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.225</td>\n",
       "      <td>35.865</td>\n",
       "      <td>51.045</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>work</td>\n",
       "      <td>17:39:00</td>\n",
       "      <td>18:17:00</td>\n",
       "      <td>13.74</td>\n",
       "      <td>35.875</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.890</td>\n",
       "      <td>51.315</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>work</td>\n",
       "      <td>13:16:00</td>\n",
       "      <td>13:19:00</td>\n",
       "      <td>15.08</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.385</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day      origin start_time  end_time  price  origin_lat  \\\n",
       "0       24    6        pool   11:58:00  12:12:00  10.00      35.650   \n",
       "1       46    2  university   21:58:00  22:18:00  11.84      35.625   \n",
       "2       27    5        pool   20:05:00  20:58:00  23.36      35.650   \n",
       "3        7    4        work   17:39:00  18:17:00  13.74      35.875   \n",
       "4       27    3        work   13:16:00  13:19:00  15.08      35.625   \n",
       "\n",
       "   origin_long  dest_lat  dest_long        dest  \n",
       "0       51.225    35.640     51.270        home  \n",
       "1       51.250    35.690     51.295  restaurant  \n",
       "2       51.225    35.865     51.045  restaurant  \n",
       "3       51.375    35.890     51.315        home  \n",
       "4       51.375    35.650     51.385  restaurant  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features and do preprocessing if needed\n",
    "# TODO\n",
    "test_data = extract_features(test_data_raw)\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: user_id\n",
      "Unique values:\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, \n",
      "===================================================\n",
      "\n",
      "Column: Day\n",
      "Unique values:\n",
      "0, 1, 2, 3, 4, 6, 5, \n",
      "===================================================\n",
      "\n",
      "Column: origin\n",
      "Unique values:\n",
      "work, restaurant, home, park, university, gym, pool, \n",
      "===================================================\n",
      "\n",
      "Column: start_time\n",
      "Unique values:\n",
      "13:07:00, 15:13:00, 20:41:00, 21:24:00, 23:38:00, 07:59:00, 21:19:00, 07:55:00, 14:11:00, 20:08:00, 21:03:00, 07:00:00, 13:50:00, 14:23:00, 21:40:00, 22:28:00, 20:28:00, 22:01:00, 12:05:00, 12:54:00, 17:29:00, 13:44:00, 14:59:00, 17:36:00, 07:49:00, 20:40:00, 22:21:00, 17:33:00, 21:51:00, 07:54:00, 13:35:00, 16:30:00, 22:35:00, 08:19:00, 11:24:00, 08:56:00, 12:17:00, 07:06:00, 07:42:00, 13:15:00, 13:53:00, 21:20:00, 07:51:00, 12:37:00, 13:40:00, 17:32:00, 20:46:00, 21:38:00, 22:07:00, 16:26:00, 20:20:00, 21:25:00, 08:05:00, 09:55:00, 12:22:00, 14:30:00, 21:01:00, 22:26:00, 07:36:00, 13:22:00, 16:09:00, 21:28:00, 22:24:00, 07:22:00, 17:38:00, 07:48:00, 17:34:00, 07:04:00, 21:07:00, 22:15:00, 20:15:00, 08:04:00, 20:16:00, 21:46:00, 07:29:00, 21:09:00, 07:32:00, 13:04:00, 21:04:00, 07:28:00, 16:45:00, 20:23:00, 21:27:00, 12:21:00, 14:07:00, 16:19:00, 13:12:00, 14:24:00, 23:31:00, 20:53:00, 21:48:00, 08:28:00, 14:15:00, 15:57:00, 16:51:00, 23:06:00, 16:52:00, 21:22:00, 07:53:00, 14:21:00, 16:53:00, 12:45:00, 14:18:00, 17:04:00, 07:24:00, 16:22:00, 11:02:00, 21:52:00, 22:49:00, 20:51:00, 07:31:00, 12:46:00, 17:42:00, 21:45:00, 07:17:00, 16:01:00, 07:08:00, 17:25:00, 07:47:00, 13:45:00, 16:28:00, 21:32:00, 09:29:00, 11:04:00, 21:41:00, 07:27:00, 16:20:00, 16:37:00, 21:53:00, 22:31:00, 07:41:00, 13:41:00, 16:10:00, 12:09:00, 17:59:00, 13:32:00, 14:27:00, 15:02:00, 21:36:00, 22:55:00, 22:27:00, 20:45:00, 22:20:00, 07:11:00, 12:44:00, 16:36:00, 12:13:00, 21:21:00, 22:03:00, 07:26:00, 17:41:00, 20:34:00, 16:54:00, 07:10:00, 15:01:00, 20:30:00, 21:43:00, 09:44:00, 07:40:00, 12:30:00, 16:48:00, 07:33:00, 07:07:00, 16:29:00, 07:02:00, 12:59:00, 13:54:00, 12:53:00, 15:03:00, 08:15:00, 11:15:00, 15:04:00, 07:15:00, 12:35:00, 21:26:00, 07:58:00, 21:05:00, 22:08:00, 16:55:00, 21:58:00, 21:35:00, 08:31:00, 14:50:00, 07:52:00, 16:00:00, 21:42:00, 07:34:00, 17:24:00, 20:05:00, 07:57:00, 16:59:00, 20:19:00, 08:50:00, 12:03:00, 14:38:00, 15:30:00, 21:31:00, 22:59:00, 09:51:00, 20:00:00, 20:42:00, 12:38:00, 13:26:00, 22:37:00, 07:23:00, 16:08:00, 22:34:00, 07:19:00, 14:32:00, 17:23:00, 20:43:00, 11:07:00, 20:33:00, 21:33:00, 16:33:00, 21:14:00, 12:36:00, 14:19:00, 21:37:00, 07:43:00, 17:26:00, 20:50:00, 13:05:00, 17:06:00, 15:45:00, 20:52:00, 22:17:00, 09:18:00, 11:08:00, 07:44:00, 22:39:00, 16:50:00, 20:31:00, 07:50:00, 14:40:00, 16:56:00, 17:40:00, 16:24:00, 12:47:00, 13:48:00, 16:31:00, 12:48:00, 22:14:00, 07:05:00, 12:19:00, 17:39:00, 13:10:00, 14:16:00, 17:17:00, 17:49:00, 20:36:00, 21:55:00, 14:37:00, 15:29:00, 08:25:00, 21:06:00, 10:23:00, 13:37:00, 18:12:00, 14:43:00, 23:42:00, 13:56:00, 11:17:00, 12:25:00, 20:11:00, 07:21:00, 10:50:00, 18:24:00, 21:44:00, 08:09:00, 14:44:00, 20:03:00, 08:06:00, 10:10:00, 10:19:00, 14:09:00, 19:12:00, 21:30:00, 08:57:00, 12:23:00, 20:35:00, 07:30:00, 11:41:00, 08:35:00, 12:24:00, 13:03:00, 13:55:00, 08:17:00, 11:53:00, 13:27:00, 08:41:00, 14:41:00, 10:12:00, 22:16:00, 08:54:00, 15:46:00, 08:29:00, 20:32:00, 14:49:00, 14:08:00, 22:19:00, 18:19:00, 08:22:00, 14:46:00, 20:07:00, 11:38:00, 07:46:00, 10:11:00, 14:17:00, 19:41:00, 21:54:00, 07:39:00, 15:00:00, 14:05:00, 11:12:00, 20:49:00, 07:35:00, 15:53:00, 18:03:00, 21:18:00, 08:13:00, 15:24:00, 12:12:00, 15:05:00, 19:35:00, 18:43:00, 14:06:00, 12:02:00, 13:33:00, 15:28:00, 07:18:00, 15:52:00, 20:47:00, 11:10:00, 20:12:00, 09:57:00, 14:39:00, 19:51:00, 21:50:00, 14:53:00, 12:49:00, 20:57:00, 13:09:00, 09:26:00, 19:01:00, 07:16:00, 20:56:00, 10:16:00, 13:36:00, 18:44:00, 22:41:00, 08:48:00, 12:16:00, 12:52:00, 11:23:00, 12:55:00, 12:20:00, 13:13:00, 12:11:00, 12:50:00, 13:47:00, 18:23:00, 11:49:00, 13:06:00, 10:47:00, 13:08:00, 07:13:00, 12:58:00, 11:45:00, 12:41:00, 18:11:00, 22:46:00, 09:31:00, 14:12:00, 14:14:00, 12:51:00, 13:38:00, 08:20:00, 09:20:00, 19:07:00, 21:11:00, 12:43:00, 18:35:00, 08:49:00, 14:13:00, 08:58:00, 12:34:00, 15:36:00, 18:38:00, 19:03:00, 21:10:00, 13:01:00, 17:21:00, 08:39:00, 11:16:00, 12:33:00, 15:42:00, 10:21:00, 11:13:00, 12:14:00, 11:11:00, 15:47:00, 17:54:00, 08:14:00, 19:25:00, 13:25:00, 18:56:00, 08:18:00, 12:00:00, 07:38:00, 11:03:00, 17:03:00, 15:21:00, 12:27:00, 21:47:00, 10:26:00, 13:00:00, 12:04:00, 17:51:00, 11:29:00, 12:01:00, 13:02:00, 09:13:00, 09:04:00, 12:06:00, 11:50:00, 18:36:00, 11:05:00, 09:23:00, 19:40:00, 08:53:00, 15:55:00, 11:27:00, 12:07:00, 18:33:00, 13:23:00, 12:31:00, 20:38:00, 10:48:00, 19:48:00, 08:21:00, 08:42:00, 10:09:00, 13:42:00, 13:31:00, 20:13:00, 07:20:00, 07:45:00, 09:40:00, 13:51:00, 12:26:00, 08:08:00, 12:08:00, 14:00:00, 09:58:00, 10:33:00, 13:28:00, 12:42:00, 13:17:00, 20:17:00, 11:01:00, 11:43:00, 18:57:00, 09:09:00, 18:10:00, 11:34:00, 06:37:00, 13:11:00, 06:35:00, 13:18:00, 13:34:00, 13:57:00, 16:06:00, 17:44:00, 20:04:00, 06:30:00, 16:46:00, 08:11:00, 11:26:00, 15:06:00, 22:10:00, 23:41:00, 17:07:00, 14:22:00, 21:16:00, 06:42:00, 23:33:00, 13:29:00, 17:30:00, 22:22:00, 14:57:00, 16:15:00, 08:01:00, 15:27:00, 06:44:00, 13:59:00, 23:39:00, 06:22:00, 17:12:00, 06:56:00, 13:19:00, 16:05:00, 14:33:00, 06:20:00, 16:44:00, 07:56:00, 22:25:00, 06:40:00, 13:20:00, 17:50:00, 08:43:00, 14:01:00, 14:45:00, 06:00:00, 06:26:00, 17:58:00, 13:43:00, 17:57:00, 20:14:00, 17:47:00, 13:30:00, 17:05:00, 08:59:00, 12:29:00, 21:29:00, 08:32:00, 07:37:00, 06:27:00, 16:41:00, 06:05:00, 12:57:00, 09:56:00, 16:11:00, 20:21:00, 14:35:00, 17:45:00, 14:20:00, 15:56:00, 08:40:00, 22:42:00, 14:51:00, 21:13:00, 22:50:00, 06:51:00, 17:02:00, 09:01:00, 11:59:00, 14:52:00, 22:36:00, 06:48:00, 06:45:00, 06:01:00, 16:03:00, 06:03:00, 23:14:00, 21:15:00, 06:39:00, 13:39:00, 13:52:00, 07:12:00, 13:58:00, 16:04:00, 16:35:00, 07:14:00, 20:09:00, 15:18:00, 16:12:00, 06:21:00, 15:41:00, 23:35:00, 17:11:00, 22:23:00, 23:00:00, 06:50:00, 06:49:00, 17:14:00, 15:39:00, 16:32:00, 06:25:00, 23:32:00, 12:18:00, 17:22:00, 20:24:00, 08:23:00, 11:00:00, 16:16:00, 14:36:00, 23:37:00, 15:43:00, 14:58:00, 11:28:00, 19:59:00, 14:26:00, 11:46:00, 11:42:00, 21:57:00, 08:24:00, 23:34:00, 11:58:00, 18:25:00, 08:55:00, 11:25:00, 08:30:00, 11:09:00, 11:19:00, 08:51:00, 11:30:00, 11:18:00, 10:05:00, 13:46:00, 08:12:00, 11:48:00, 11:14:00, 11:21:00, 11:40:00, 09:37:00, 21:34:00, 11:52:00, 19:43:00, 19:30:00, 15:58:00, 08:10:00, 12:32:00, 10:17:00, 18:42:00, 20:26:00, 11:56:00, 20:39:00, 22:56:00, 20:06:00, 15:40:00, 11:57:00, 08:27:00, 14:03:00, 12:10:00, 11:36:00, 18:28:00, 06:59:00, 06:29:00, 20:22:00, 06:41:00, 22:47:00, 12:40:00, 18:37:00, 06:09:00, 13:14:00, 21:56:00, 07:25:00, 20:29:00, 10:59:00, 18:29:00, 07:03:00, 20:44:00, 06:19:00, 06:32:00, 11:37:00, 21:02:00, 09:22:00, 21:59:00, 06:46:00, 21:12:00, 14:54:00, 18:15:00, 17:43:00, 20:27:00, 11:31:00, 15:19:00, 18:54:00, 11:39:00, 21:00:00, 06:17:00, 12:56:00, 20:58:00, 20:59:00, 06:18:00, 21:08:00, 06:53:00, 14:04:00, 11:06:00, 21:39:00, 18:48:00, 21:17:00, 06:47:00, 11:20:00, 16:58:00, 10:27:00, 11:22:00, 18:00:00, 09:38:00, 19:38:00, 06:13:00, 06:43:00, 15:16:00, 06:23:00, 06:16:00, 17:48:00, 06:38:00, 13:49:00, 16:13:00, 17:28:00, 16:49:00, 22:09:00, 22:29:00, 22:40:00, 06:10:00, 16:34:00, 14:55:00, 13:16:00, 17:15:00, 20:55:00, 14:31:00, 16:25:00, 14:48:00, 06:15:00, 17:46:00, 06:31:00, 16:21:00, 06:02:00, 16:42:00, 22:32:00, 15:17:00, 17:55:00, 06:14:00, 16:43:00, 17:16:00, 08:45:00, 20:10:00, 22:02:00, 16:57:00, 22:00:00, 09:00:00, 12:15:00, 20:37:00, 07:09:00, 09:10:00, 08:47:00, 17:35:00, 20:18:00, 06:52:00, 16:14:00, 06:04:00, 07:01:00, 16:07:00, 14:28:00, 22:04:00, 09:17:00, 14:10:00, 17:19:00, 17:08:00, 14:02:00, 15:22:00, 22:18:00, 15:50:00, 17:37:00, 17:27:00, 16:40:00, 23:36:00, 17:10:00, 08:34:00, 17:01:00, 17:09:00, 09:24:00, 11:54:00, 16:23:00, 17:56:00, 23:44:00, 16:18:00, 23:07:00, 23:30:00, 08:16:00, 09:28:00, 21:49:00, 23:18:00, 23:43:00, 23:16:00, 09:34:00, 09:14:00, 22:38:00, 08:02:00, 15:35:00, 09:54:00, 12:28:00, 13:21:00, 16:39:00, 23:05:00, 16:17:00, 22:45:00, 23:21:00, 22:30:00, 14:25:00, 22:05:00, 23:17:00, 15:26:00, 23:46:00, 17:00:00, 16:27:00, 23:40:00, 14:34:00, 08:37:00, 15:49:00, 13:24:00, 12:39:00, 17:13:00, 09:33:00, 20:54:00, 17:18:00, 09:02:00, 22:13:00, 15:54:00, 20:25:00, 09:47:00, 15:12:00, 22:12:00, 16:02:00, 17:31:00, 17:20:00, 06:07:00, 20:02:00, 15:09:00, 06:12:00, 09:32:00, 11:47:00, 06:57:00, 16:47:00, 09:07:00, 08:07:00, 17:53:00, 09:05:00, 06:28:00, 06:58:00, 17:52:00, 22:58:00, 06:06:00, 11:33:00, 09:53:00, 06:08:00, 06:36:00, 15:07:00, 06:55:00, 06:34:00, 22:43:00, 09:06:00, 09:21:00, 22:57:00, 14:56:00, 08:38:00, 06:33:00, 15:37:00, 06:54:00, 09:49:00, 09:50:00, 09:42:00, 22:11:00, 08:26:00, 14:42:00, 09:15:00, 08:33:00, 15:48:00, 23:27:00, 19:53:00, 08:44:00, 10:42:00, 15:20:00, 10:08:00, 10:01:00, 20:48:00, 10:43:00, 19:34:00, 14:29:00, 21:23:00, 18:41:00, 10:52:00, 14:47:00, 20:01:00, 15:25:00, 15:38:00, 09:03:00, 06:24:00, 11:44:00, 11:35:00, 23:09:00, 16:38:00, 23:48:00, 15:32:00, 09:25:00, 06:11:00, 15:23:00, 15:08:00, 08:03:00, 15:34:00, 15:10:00, 09:08:00, 23:03:00, 11:55:00, 09:11:00, 23:47:00, 08:00:00, 23:50:00, 15:15:00, 09:41:00, 15:31:00, 15:59:00, 08:52:00, 09:52:00, 11:51:00, 23:45:00, 10:37:00, 10:28:00, 18:21:00, 19:44:00, 19:21:00, 22:48:00, 19:10:00, 18:13:00, 18:26:00, 09:12:00, 10:30:00, 19:00:00, 19:58:00, 22:33:00, 09:35:00, 10:51:00, 19:29:00, 09:59:00, 15:14:00, 09:48:00, 09:16:00, 18:51:00, 23:53:00, 18:55:00, 19:47:00, 18:53:00, 10:02:00, 19:15:00, 09:30:00, 09:36:00, 23:49:00, 10:13:00, 19:19:00, 10:22:00, 19:13:00, 18:08:00, 19:54:00, 18:39:00, 15:51:00, 10:15:00, 10:54:00, 19:09:00, 08:36:00, 18:18:00, 09:45:00, 10:29:00, 15:11:00, 11:32:00, 22:53:00, 23:24:00, 22:54:00, 09:43:00, 22:52:00, 22:44:00, 19:37:00, 10:38:00, 18:47:00, 10:44:00, 08:46:00, 10:55:00, 10:40:00, 09:39:00, 09:27:00, 18:01:00, 09:19:00, 10:03:00, 19:56:00, 10:04:00, 18:32:00, 18:07:00, 19:55:00, 23:51:00, 19:27:00, 19:32:00, 22:06:00, 22:51:00, 23:04:00, 23:10:00, 10:39:00, 10:25:00, 19:33:00, 18:46:00, 19:46:00, 18:30:00, 18:31:00, 18:58:00, 23:02:00, 23:01:00, 23:08:00, 23:52:00, 10:49:00, 19:23:00, 19:42:00, 19:26:00, 18:06:00, 23:56:00, 10:06:00, 19:08:00, 15:33:00, 23:29:00, 23:13:00, 09:46:00, 23:15:00, 23:54:00, 23:57:00, 19:57:00, 18:16:00, 18:04:00, 18:45:00, 18:27:00, 10:24:00, 19:45:00, 18:05:00, 18:22:00, 18:50:00, 18:59:00, 15:44:00, 10:32:00, 19:05:00, 18:17:00, 19:14:00, 18:14:00, 18:34:00, 10:14:00, 10:00:00, 23:12:00, 19:04:00, 19:31:00, 19:36:00, 23:11:00, \n",
      "===================================================\n",
      "\n",
      "Column: end_time\n",
      "Unique values:\n",
      "14:43:00, 16:49:00, 20:54:00, 21:37:00, 23:58:00, 08:19:00, 21:49:00, 08:09:00, 14:49:00, 20:33:00, 21:25:00, 07:20:00, 13:53:00, 14:29:00, 21:58:00, 22:50:00, 21:31:00, 23:04:00, 12:24:00, 13:14:00, 18:01:00, 15:39:00, 18:09:00, 09:37:00, 21:51:00, 23:44:00, 18:08:00, 22:46:00, 08:50:00, 14:07:00, 17:00:00, 22:05:00, 23:54:00, 09:01:00, 12:01:00, 09:32:00, 12:49:00, 07:28:00, 07:56:00, 13:23:00, 14:01:00, 21:34:00, 08:05:00, 13:10:00, 14:18:00, 17:50:00, 21:08:00, 21:56:00, 22:21:00, 08:13:00, 16:59:00, 20:55:00, 21:54:00, 08:41:00, 10:36:00, 12:55:00, 15:24:00, 23:22:00, 07:55:00, 13:54:00, 16:23:00, 22:48:00, 07:39:00, 17:51:00, 08:03:00, 18:11:00, 18:10:00, 21:45:00, 22:52:00, 20:47:00, 13:01:00, 21:16:00, 22:47:00, 07:49:00, 21:36:00, 07:45:00, 13:29:00, 20:34:00, 21:18:00, 07:41:00, 17:02:00, 20:57:00, 22:02:00, 13:37:00, 15:20:00, 16:37:00, 22:03:00, 07:48:00, 15:13:00, 23:50:00, 22:14:00, 09:06:00, 15:27:00, 17:07:00, 17:27:00, 23:42:00, 08:02:00, 17:26:00, 08:12:00, 13:51:00, 14:27:00, 17:24:00, 21:22:00, 13:48:00, 15:19:00, 16:54:00, 11:42:00, 22:19:00, 23:15:00, 22:41:00, 07:50:00, 13:15:00, 18:15:00, 07:36:00, 16:32:00, 07:21:00, 15:14:00, 17:58:00, 08:01:00, 14:17:00, 07:58:00, 22:22:00, 10:09:00, 11:39:00, 23:01:00, 08:37:00, 08:07:00, 22:01:00, 22:40:00, 13:46:00, 16:44:00, 20:31:00, 21:13:00, 13:17:00, 18:17:00, 13:57:00, 14:50:00, 16:50:00, 22:11:00, 17:01:00, 21:50:00, 23:30:00, 23:56:00, 12:58:00, 17:13:00, 12:47:00, 07:24:00, 21:33:00, 22:25:00, 17:54:00, 21:47:00, 08:21:00, 17:29:00, 07:30:00, 14:31:00, 15:41:00, 18:05:00, 22:26:00, 10:19:00, 13:36:00, 17:20:00, 17:11:00, 07:26:00, 22:44:00, 07:19:00, 13:24:00, 14:33:00, 08:49:00, 11:55:00, 12:44:00, 22:31:00, 08:43:00, 21:38:00, 22:36:00, 08:08:00, 17:34:00, 09:09:00, 13:25:00, 15:31:00, 16:43:00, 08:11:00, 22:07:00, 22:18:00, 17:42:00, 21:35:00, 08:15:00, 17:30:00, 07:33:00, 21:10:00, 12:36:00, 15:00:00, 15:51:00, 22:29:00, 23:53:00, 10:26:00, 20:12:00, 20:51:00, 07:46:00, 12:56:00, 13:44:00, 23:26:00, 07:38:00, 16:41:00, 22:04:00, 07:35:00, 20:56:00, 21:48:00, 07:47:00, 11:47:00, 21:03:00, 07:22:00, 17:05:00, 13:49:00, 18:13:00, 22:51:00, 08:45:00, 16:52:00, 07:17:00, 18:03:00, 21:06:00, 12:35:00, 21:23:00, 16:16:00, 23:14:00, 09:56:00, 11:50:00, 22:09:00, 22:56:00, 08:06:00, 17:25:00, 21:26:00, 17:32:00, 23:45:00, 09:53:00, 13:18:00, 14:21:00, 13:20:00, 21:44:00, 12:37:00, 14:52:00, 17:35:00, 18:20:00, 21:12:00, 22:15:00, 16:21:00, 21:57:00, 22:35:00, 07:37:00, 15:03:00, 07:59:00, 15:57:00, 09:04:00, 21:19:00, 11:16:00, 14:42:00, 18:26:00, 22:17:00, 15:46:00, 09:23:00, 15:29:00, 20:46:00, 13:26:00, 14:16:00, 20:53:00, 21:15:00, 08:32:00, 12:19:00, 19:12:00, 08:38:00, 15:10:00, 20:44:00, 09:16:00, 15:37:00, 22:06:00, 11:09:00, 14:32:00, 11:20:00, 15:08:00, 09:29:00, 13:07:00, 21:39:00, 11:11:00, 12:08:00, 12:43:00, 14:09:00, 11:21:00, 14:56:00, 08:20:00, 12:57:00, 08:55:00, 23:51:00, 11:12:00, 23:17:00, 09:21:00, 16:19:00, 22:42:00, 10:01:00, 08:23:00, 15:15:00, 14:40:00, 23:38:00, 18:24:00, 15:21:00, 12:23:00, 13:11:00, 16:27:00, 19:52:00, 15:32:00, 08:16:00, 20:29:00, 14:35:00, 08:28:00, 21:53:00, 12:18:00, 21:04:00, 07:54:00, 07:31:00, 16:25:00, 18:19:00, 21:52:00, 08:46:00, 15:54:00, 15:34:00, 19:56:00, 18:57:00, 09:50:00, 13:03:00, 16:00:00, 21:59:00, 16:24:00, 21:29:00, 12:00:00, 13:42:00, 20:41:00, 15:44:00, 20:37:00, 22:34:00, 09:26:00, 08:18:00, 12:51:00, 14:10:00, 10:33:00, 15:47:00, 19:47:00, 22:30:00, 07:51:00, 21:11:00, 08:17:00, 14:46:00, 11:17:00, 18:59:00, 22:58:00, 09:15:00, 12:22:00, 13:19:00, 12:25:00, 14:03:00, 14:00:00, 14:02:00, 16:01:00, 20:48:00, 08:40:00, 21:40:00, 12:41:00, 14:19:00, 13:45:00, 13:05:00, 14:14:00, 11:08:00, 13:32:00, 14:39:00, 12:02:00, 18:14:00, 23:10:00, 10:04:00, 07:40:00, 13:47:00, 17:59:00, 13:08:00, 08:51:00, 21:05:00, 15:45:00, 20:13:00, 12:40:00, 13:16:00, 19:06:00, 09:25:00, 14:45:00, 09:27:00, 16:09:00, 19:04:00, 19:45:00, 08:59:00, 14:47:00, 21:14:00, 12:31:00, 17:57:00, 09:03:00, 12:03:00, 16:08:00, 13:12:00, 11:27:00, 14:30:00, 22:45:00, 11:44:00, 11:54:00, 16:20:00, 13:38:00, 08:26:00, 16:11:00, 21:42:00, 19:31:00, 08:34:00, 11:46:00, 13:13:00, 08:48:00, 13:39:00, 13:22:00, 17:41:00, 15:50:00, 10:58:00, 13:35:00, 22:28:00, 14:08:00, 12:07:00, 13:56:00, 12:32:00, 09:41:00, 20:06:00, 08:30:00, 12:39:00, 12:29:00, 09:40:00, 20:25:00, 12:14:00, 11:49:00, 13:06:00, 12:45:00, 18:46:00, 08:44:00, 12:53:00, 11:07:00, 20:02:00, 22:37:00, 08:47:00, 17:18:00, 09:08:00, 13:02:00, 13:43:00, 23:47:00, 14:41:00, 20:35:00, 23:43:00, 20:30:00, 14:36:00, 14:51:00, 10:12:00, 13:21:00, 14:38:00, 08:00:00, 13:30:00, 14:59:00, 12:52:00, 11:05:00, 14:13:00, 11:10:00, 16:51:00, 07:42:00, 13:58:00, 11:13:00, 11:57:00, 19:09:00, 09:42:00, 18:55:00, 22:16:00, 06:57:00, 12:28:00, 06:54:00, 10:23:00, 21:21:00, 22:39:00, 14:15:00, 21:28:00, 23:19:00, 06:46:00, 17:31:00, 17:17:00, 09:05:00, 12:13:00, 15:33:00, 23:57:00, 14:55:00, 08:10:00, 13:52:00, 07:04:00, 12:59:00, 09:02:00, 22:13:00, 08:52:00, 13:27:00, 14:57:00, 15:48:00, 07:05:00, 17:48:00, 06:44:00, 17:46:00, 07:11:00, 13:28:00, 08:53:00, 15:35:00, 23:18:00, 22:10:00, 14:44:00, 06:40:00, 17:23:00, 21:55:00, 06:59:00, 09:34:00, 12:15:00, 15:02:00, 06:22:00, 15:07:00, 06:42:00, 18:30:00, 06:19:00, 17:09:00, 16:36:00, 18:25:00, 06:43:00, 14:11:00, 09:49:00, 20:59:00, 09:19:00, 06:47:00, 16:58:00, 06:23:00, 15:36:00, 17:21:00, 16:48:00, 10:46:00, 15:11:00, 15:55:00, 18:27:00, 15:26:00, 16:17:00, 09:35:00, 07:03:00, 22:20:00, 23:59:00, 16:10:00, 07:13:00, 13:04:00, 17:39:00, 21:32:00, 09:54:00, 15:04:00, 23:11:00, 07:00:00, 17:55:00, 06:18:00, 17:45:00, 16:39:00, 06:20:00, 09:38:00, 23:55:00, 13:09:00, 14:05:00, 23:33:00, 07:18:00, 15:40:00, 16:42:00, 07:53:00, 15:22:00, 09:48:00, 17:53:00, 20:40:00, 23:39:00, 08:14:00, 16:29:00, 18:06:00, 22:33:00, 23:46:00, 14:54:00, 18:12:00, 07:07:00, 15:09:00, 10:06:00, 07:34:00, 12:11:00, 12:48:00, 20:26:00, 09:18:00, 16:55:00, 14:06:00, 13:41:00, 23:28:00, 08:04:00, 18:02:00, 09:12:00, 16:03:00, 11:59:00, 10:05:00, 13:33:00, 22:59:00, 19:58:00, 16:02:00, 23:06:00, 23:52:00, 13:50:00, 19:13:00, 23:37:00, 10:00:00, 11:36:00, 22:32:00, 15:30:00, 13:34:00, 09:33:00, 11:48:00, 16:46:00, 11:37:00, 08:27:00, 11:56:00, 15:53:00, 14:23:00, 20:49:00, 09:39:00, 14:48:00, 09:13:00, 11:18:00, 12:42:00, 11:53:00, 09:36:00, 18:56:00, 10:40:00, 22:08:00, 09:57:00, 20:21:00, 12:33:00, 12:50:00, 11:06:00, 20:00:00, 08:39:00, 12:27:00, 13:59:00, 07:27:00, 20:15:00, 09:11:00, 12:20:00, 08:29:00, 14:12:00, 18:53:00, 12:30:00, 23:12:00, 09:17:00, 21:24:00, 11:43:00, 13:55:00, 16:07:00, 07:16:00, 21:01:00, 07:14:00, 13:31:00, 23:48:00, 08:22:00, 12:10:00, 20:01:00, 06:29:00, 20:23:00, 19:49:00, 06:45:00, 15:25:00, 11:22:00, 16:47:00, 07:52:00, 06:56:00, 15:38:00, 19:00:00, 20:45:00, 20:58:00, 16:06:00, 07:15:00, 12:17:00, 16:34:00, 21:46:00, 06:26:00, 21:27:00, 07:43:00, 22:55:00, 07:06:00, 12:06:00, 17:40:00, 22:38:00, 22:53:00, 13:00:00, 22:12:00, 19:24:00, 18:31:00, 11:40:00, 12:21:00, 23:00:00, 19:01:00, 23:02:00, 06:39:00, 22:24:00, 11:41:00, 19:14:00, 07:32:00, 19:59:00, 11:58:00, 06:58:00, 07:01:00, 12:38:00, 08:33:00, 21:07:00, 19:26:00, 06:37:00, 18:42:00, 19:27:00, 22:00:00, 07:12:00, 18:29:00, 14:25:00, 17:28:00, 15:18:00, 17:19:00, 18:00:00, 19:18:00, 21:09:00, 19:25:00, 06:53:00, 10:50:00, 10:25:00, 20:50:00, 17:44:00, 22:43:00, 06:55:00, 17:08:00, 23:16:00, 06:34:00, 23:13:00, 18:52:00, 20:38:00, 06:31:00, 12:46:00, 06:38:00, 14:22:00, 18:22:00, 17:33:00, 10:59:00, 16:57:00, 08:54:00, 18:43:00, 18:40:00, 08:25:00, 15:28:00, 19:28:00, 06:30:00, 14:04:00, 18:50:00, 17:14:00, 06:32:00, 07:29:00, 16:40:00, 16:04:00, 20:39:00, 06:33:00, 06:36:00, 06:48:00, 23:35:00, 16:22:00, 23:31:00, 07:08:00, 19:23:00, 17:52:00, 23:03:00, 06:50:00, 15:17:00, 18:39:00, 21:20:00, 21:30:00, 06:35:00, 23:49:00, 15:05:00, 23:32:00, 18:44:00, 09:46:00, 10:32:00, 19:40:00, 14:20:00, 06:27:00, 18:33:00, 10:45:00, 15:42:00, 17:16:00, 18:18:00, 20:22:00, 18:41:00, 15:01:00, 17:06:00, 09:59:00, 17:43:00, 17:49:00, 08:58:00, 19:03:00, 17:38:00, 16:15:00, 18:34:00, 17:04:00, 07:23:00, 23:05:00, 16:45:00, 10:02:00, 09:10:00, 07:57:00, 17:56:00, 23:27:00, 21:17:00, 16:14:00, 10:08:00, 08:35:00, 23:36:00, 15:06:00, 12:34:00, 15:43:00, 23:40:00, 16:12:00, 23:25:00, 10:27:00, 22:27:00, 22:54:00, 22:57:00, 09:28:00, 07:44:00, 11:04:00, 18:35:00, 19:08:00, 21:00:00, 18:32:00, 18:07:00, 20:32:00, 23:24:00, 16:53:00, 18:49:00, 17:37:00, 15:52:00, 12:16:00, 23:08:00, 23:09:00, 13:40:00, 18:16:00, 18:58:00, 12:26:00, 23:20:00, 09:22:00, 10:39:00, 14:53:00, 18:04:00, 11:25:00, 16:56:00, 18:21:00, 14:58:00, 17:03:00, 14:26:00, 10:35:00, 10:53:00, 16:26:00, 16:35:00, 10:13:00, 07:09:00, 17:22:00, 20:36:00, 21:43:00, 23:07:00, 20:43:00, 14:28:00, 10:28:00, 16:38:00, 10:41:00, 06:24:00, 15:16:00, 06:28:00, 06:25:00, 15:58:00, 22:23:00, 20:27:00, 06:51:00, 10:03:00, 06:41:00, 17:47:00, 09:44:00, 14:37:00, 16:28:00, 06:21:00, 10:16:00, 07:10:00, 15:12:00, 09:45:00, 22:49:00, 18:48:00, 18:47:00, 20:14:00, 20:05:00, 21:41:00, 11:00:00, 09:20:00, 06:52:00, 07:02:00, 17:15:00, 17:10:00, 10:55:00, 11:01:00, 14:34:00, 18:45:00, 06:49:00, 17:36:00, 14:24:00, 20:10:00, 19:11:00, 09:51:00, 11:51:00, 20:16:00, 08:42:00, 10:30:00, 11:23:00, 08:24:00, 11:52:00, 15:56:00, 20:07:00, 09:00:00, 12:54:00, 19:54:00, 15:59:00, 20:42:00, 08:57:00, 09:14:00, 11:35:00, 09:55:00, 16:31:00, 20:09:00, 09:47:00, 10:24:00, 10:38:00, 16:05:00, 18:23:00, 10:29:00, 16:18:00, 07:25:00, 12:12:00, 20:20:00, 08:31:00, 15:23:00, 20:28:00, 18:28:00, 10:21:00, 18:37:00, 18:38:00, 19:22:00, 18:36:00, 09:30:00, 09:31:00, 19:20:00, 09:07:00, 11:14:00, 12:04:00, 16:30:00, 10:37:00, 11:15:00, 08:56:00, 19:07:00, 19:10:00, 18:51:00, 19:16:00, 09:52:00, 06:17:00, 15:49:00, 06:15:00, 10:11:00, 20:52:00, 10:54:00, 19:37:00, 09:58:00, 12:09:00, 10:49:00, 11:29:00, 11:38:00, 20:17:00, 19:30:00, 10:17:00, 10:18:00, 10:07:00, 12:05:00, 19:15:00, 21:02:00, 19:48:00, 10:20:00, 19:57:00, 10:14:00, 19:51:00, 19:17:00, 23:21:00, 10:43:00, 11:19:00, 19:21:00, 16:33:00, 16:13:00, 10:48:00, 17:12:00, 11:26:00, 23:34:00, 10:42:00, 11:45:00, 09:43:00, 23:29:00, 09:24:00, 08:36:00, 10:57:00, 11:34:00, 10:56:00, 20:24:00, 19:38:00, 20:19:00, 19:02:00, 10:22:00, 19:50:00, 11:24:00, 11:30:00, 10:34:00, 10:10:00, 19:33:00, 10:31:00, 10:47:00, 23:41:00, 11:33:00, 11:31:00, 19:53:00, 10:52:00, 11:28:00, 19:44:00, 19:05:00, 18:54:00, 19:43:00, 20:18:00, 20:03:00, 06:11:00, 06:08:00, 19:34:00, 19:32:00, 19:35:00, 06:09:00, 10:44:00, 23:23:00, 10:15:00, 06:14:00, 06:12:00, 06:16:00, 10:51:00, 19:29:00, 11:32:00, 19:46:00, 19:19:00, 19:41:00, 19:39:00, 20:08:00, 19:36:00, 20:11:00, 11:02:00, 06:10:00, 06:05:00, 06:13:00, 06:07:00, 19:42:00, \n",
      "===================================================\n",
      "\n",
      "Column: price\n",
      "Unique values:\n",
      "43.99, 36.66, 15.08, 10.0, 19.48, 16.83, 13.24, 27.49, 21.38, 13.94, 16.49, 11.39, 14.78, 19.09, 21.43, 21.84, 16.58, 15.41, 10.81, 17.99, 20.58, 21.49, 41.28, 24.26, 28.17, 15.75, 30.4, 30.53, 20.24, 23.26, 41.64, 32.46, 15.74, 22.39, 13.49, 16.22, 20.86, 19.23, 10.98, 11.79, 20.56, 12.78, 15.16, 20.46, 11.14, 14.6, 17.8, 17.28, 23.51, 23.17, 14.44, 18.61, 30.68, 22.97, 18.76, 34.41, 22.32, 13.93, 15.3, 19.32, 15.84, 19.84, 11.88, 17.4, 15.24, 11.85, 14.04, 25.28, 31.4, 22.99, 13.4, 18.47, 12.19, 12.26, 17.46, 20.63, 11.13, 39.08, 34.17, 15.65, 17.85, 21.87, 23.95, 31.04, 28.85, 14.21, 25.1, 13.87, 12.37, 10.09, 15.59, 24.44, 30.22, 26.58, 15.49, 17.58, 20.52, 26.62, 20.3, 14.02, 24.48, 19.13, 18.29, 24.59, 17.69, 21.22, 19.45, 22.15, 15.18, 18.37, 14.95, 21.37, 25.48, 28.55, 21.61, 26.66, 34.43, 35.8, 16.38, 23.81, 15.62, 17.23, 13.74, 18.6, 18.49, 13.0, 28.43, 10.69, 13.13, 17.08, 11.89, 44.25, 13.83, 27.13, 20.16, 16.42, 20.84, 26.54, 31.22, 13.86, 18.03, 19.41, 15.56, 13.47, 15.86, 13.6, 13.29, 15.76, 17.45, 16.56, 22.91, 17.01, 18.25, 25.64, 21.68, 31.09, 21.99, 14.13, 13.67, 16.52, 13.78, 11.03, 17.62, 30.49, 37.81, 43.83, 25.88, 12.85, 19.37, 11.18, 18.19, 16.67, 32.98, 21.25, 11.77, 18.41, 13.15, 17.55, 15.87, 20.04, 10.93, 26.82, 20.36, 21.86, 27.34, 12.52, 17.51, 16.61, 32.69, 23.2, 18.68, 24.22, 21.76, 29.52, 24.86, 14.48, 13.28, 24.96, 26.79, 12.77, 15.42, 11.78, 11.82, 21.95, 18.51, 20.83, 14.38, 25.23, 10.79, 15.1, 17.3, 18.79, 10.48, 19.4, 14.86, 13.52, 24.29, 16.57, 15.45, 31.97, 13.07, 12.27, 27.14, 29.53, 31.53, 29.87, 18.99, 11.5, 16.47, 19.64, 20.09, 12.82, 23.6, 27.08, 26.95, 25.79, 17.67, 19.17, 21.59, 14.93, 23.4, 34.7, 25.5, 33.46, 12.93, 37.59, 22.09, 14.59, 31.76, 11.76, 15.63, 13.72, 27.33, 18.7, 16.64, 14.96, 13.77, 13.16, 18.94, 25.53, 23.07, 23.24, 32.3, 10.15, 19.93, 12.53, 19.46, 10.67, 15.04, 23.82, 16.9, 31.73, 35.43, 10.25, 26.31, 14.41, 27.68, 14.61, 23.72, 15.97, 25.07, 23.63, 36.33, 36.97, 17.91, 22.87, 14.87, 28.2, 32.0, 25.63, 24.63, 32.83, 21.08, 19.72, 29.57, 26.63, 18.83, 21.26, 32.8, 29.17, 15.57, 13.81, 10.3, 35.81, 28.04, 24.84, 12.34, 10.77, 23.53, 21.45, 16.37, 21.01, 31.48, 26.4, 17.37, 22.44, 31.5, 43.66, 29.28, 34.27, 13.66, 21.6, 20.17, 38.63, 32.09, 24.6, 14.83, 15.23, 12.47, 12.71, 22.85, 10.43, 23.86, 21.0, 19.33, 26.0, 32.68, 10.1, 21.66, 22.4, 22.02, 28.18, 21.29, 14.01, 28.86, 19.82, 13.84, 13.58, 13.53, 23.58, 20.99, 16.59, 23.21, 21.82, 24.72, 13.1, 22.92, 23.34, 33.27, 33.29, 32.25, 25.75, 17.16, 19.63, 17.78, 22.19, 32.22, 32.51, 14.63, 35.29, 32.07, 25.76, 21.62, 21.73, 16.27, 17.94, 10.36, 19.06, 21.75, 15.54, 26.04, 25.77, 33.14, 24.49, 30.03, 17.75, 13.14, 30.97, 29.13, 17.36, 13.61, 21.96, 25.46, 24.53, 26.43, 30.48, 37.29, 17.1, 36.26, 34.77, 20.7, 16.5, 14.52, 21.88, 11.62, 10.83, 20.29, 13.12, 23.48, 23.32, 14.18, 23.66, 17.93, 14.56, 11.34, 16.19, 16.34, 22.79, 16.77, 20.9, 16.63, 36.77, 34.2, 22.29, 15.71, 17.09, 22.8, 17.84, 27.86, 22.66, 25.7, 11.92, 24.24, 21.8, 10.99, 23.56, 24.17, 22.01, 20.79, 20.37, 22.1, 18.98, 11.68, 24.57, 27.94, 21.57, 18.48, 27.5, 17.29, 33.17, 28.0, 26.81, 26.72, 12.62, 20.59, 25.24, 20.54, 24.41, 23.12, 22.2, 15.37, 10.96, 13.36, 17.43, 22.04, 14.7, 21.53, 31.94, 11.97, 14.9, 18.21, 19.9, 30.34, 15.09, 17.38, 17.54, 14.55, 34.99, 22.76, 27.17, 20.94, 34.44, 19.95, 22.0, 13.85, 19.56, 14.74, 32.39, 14.15, 30.24, 35.39, 20.44, 23.22, 31.57, 25.98, 12.31, 21.65, 12.36, 11.51, 10.72, 16.94, 22.38, 27.02, 18.84, 14.07, 20.72, 22.42, 10.04, 21.17, 21.83, 25.89, 13.34, 20.08, 24.55, 20.6, 30.66, 12.94, 11.63, 20.22, 22.52, 22.73, 12.5, 39.74, 42.59, 17.72, 22.51, 10.85, 10.63, 15.06, 22.68, 23.94, 37.58, 25.36, 33.04, 28.1, 12.54, 21.24, 19.8, 27.58, 11.91, 22.06, 16.95, 19.03, 27.32, 10.24, 17.31, 13.2, 31.54, 25.94, 24.27, 21.27, 22.41, 34.67, 22.78, 12.25, 26.87, 15.85, 15.27, 11.99, 21.67, 18.59, 36.34, 13.5, 19.75, 18.77, 20.74, 13.21, 18.17, 19.89, 20.06, 18.39, 13.26, 31.52, 20.03, 27.8, 18.0, 10.22, 13.22, 23.9, 12.29, 34.47, 16.86, 16.8, 13.54, 32.72, 30.44, 19.83, 24.28, 12.75, 20.31, 19.21, 12.04, 13.82, 14.34, 13.96, 13.11, 19.22, 20.48, 27.31, 15.17, 19.2, 12.6, 23.23, 28.37, 17.56, 14.67, 14.54, 12.87, 19.38, 10.13, 22.35, 11.86, 14.97, 17.32, 17.89, 38.0, 30.59, 37.5, 18.07, 23.25, 20.55, 24.02, 19.51, 15.39, 10.66, 14.25, 10.57, 17.76, 14.77, 21.91, 22.24, 20.28, 15.19, 21.13, 28.19, 19.99, 20.95, 18.62, 27.95, 16.39, 14.75, 26.83, 11.43, 22.43, 13.65, 14.69, 15.02, 18.86, 15.13, 26.11, 30.27, 13.18, 14.08, 21.15, 18.3, 36.46, 33.9, 16.6, 17.87, 24.09, 28.84, 14.1, 19.36, 26.08, 24.3, 18.92, 16.35, 21.5, 16.81, 28.51, 30.32, 17.25, 19.65, 25.21, 23.43, 30.15, 25.4, 27.65, 18.05, 10.18, 21.41, 41.22, 14.57, 26.49, 31.34, 12.21, 15.66, 16.76, 13.37, 18.11, 20.5, 16.88, 14.46, 12.43, 17.02, 30.29, 20.66, 20.51, 20.41, 20.42, 16.13, 16.2, 30.51, 37.26, 16.15, 19.11, 21.11, 22.53, 25.85, 15.91, 19.08, 29.96, 30.73, 22.75, 17.03, 20.47, 26.56, 35.78, 19.43, 29.47, 31.01, 20.1, 34.36, 10.61, 26.39, 36.94, 20.98, 15.68, 11.61, 26.61, 15.12, 20.21, 27.59, 18.75, 21.9, 18.46, 11.45, 21.77, 25.18, 23.54, 24.89, 13.27, 14.22, 35.45, 16.46, 24.15, 11.87, 20.62, 25.19, 22.5, 14.31, 21.33, 18.15, 40.08, 12.97, 12.24, 12.72, 28.38, 28.26, 22.94, 22.03, 10.34, 12.56, 30.84, 15.25, 35.08, 33.37, 31.13, 11.08, 25.56, 25.61, 10.35, 19.74, 31.98, 25.08, 31.88, 23.01, 25.11, 37.94, 27.19, 22.12, 10.64, 38.14, 22.86, 22.36, 33.28, 32.97, 14.73, 27.93, 31.15, 12.01, 13.33, 15.52, 17.24, 11.72, 24.37, 25.31, 23.97, 25.33, 29.5, 31.3, 13.79, 26.92, 10.58, 20.19, 28.03, 28.35, 30.09, 29.6, 25.25, 37.16, 14.8, 16.31, 26.16, 35.18, 25.05, 11.52, 18.58, 29.54, 20.65, 25.13, 35.85, 25.14, 16.91, 23.96, 22.46, 10.7, 14.43, 23.77, 34.19, 20.11, 21.58, 17.86, 26.53, 28.73, 26.93, 14.49, 14.14, 17.88, 25.3, 18.35, 33.87, 21.36, 33.23, 34.86, 22.7, 11.38, 10.32, 22.07, 19.3, 12.33, 30.39, 25.69, 25.26, 19.34, 30.74, 44.03, 29.62, 23.14, 27.35, 27.55, 17.79, 23.45, 27.07, 11.81, 16.79, 33.34, 13.35, 18.43, 29.3, 14.37, 35.75, 37.62, 19.27, 20.89, 31.49, 24.35, 10.6, 14.58, 31.91, 29.91, 22.05, 26.1, 11.47, 15.89, 23.44, 30.38, 23.64, 34.13, 11.59, 21.89, 33.5, 10.46, 28.83, 24.46, 15.72, 16.01, 32.08, 30.71, 16.11, 29.99, 32.76, 34.11, 15.5, 21.04, 19.28, 21.79, 20.53, 13.91, 17.73, 33.93, 26.5, 12.0, 31.19, 35.09, 31.02, 28.93, 17.57, 23.35, 17.81, 12.66, 11.01, 51.18, 17.0, 46.84, 52.9, 14.91, 22.58, 41.09, 33.78, 23.79, 32.44, 22.71, 25.8, 19.96, 48.88, 48.45, 42.77, 31.14, 26.97, 33.62, 24.62, 27.03, 39.19, 39.24, 12.44, 35.69, 26.74, 23.84, 50.92, 28.25, 14.2, 24.4, 31.47, 30.42, 10.59, 16.93, 42.33, 12.79, 16.89, 22.54, 10.75, 24.88, 20.77, 12.84, 21.63, 20.2, 22.62, 15.95, 41.51, 33.12, 27.46, 34.24, 12.3, 25.09, 21.64, 31.26, 15.93, 26.28, 44.51, 16.28, 12.99, 14.29, 23.11, 23.83, 46.41, 21.07, 28.5, 41.9, 35.15, 19.25, 29.93, 45.76, 19.5, 19.24, 19.12, 18.74, 18.24, 27.61, 25.93, 32.21, 28.81, 20.68, 23.76, 24.99, 18.12, 23.47, 10.88, 30.17, 17.64, 21.55, 24.42, 11.4, 15.83, 43.76, 43.0, 21.09, 30.69, 41.61, 29.82, 11.54, 23.87, 30.0, 24.03, 32.05, 41.11, 10.65, 19.0, 42.52, 25.2, 14.81, 16.45, 15.29, 20.87, 31.89, 29.72, 22.14, 23.73, 17.39, 17.44, 33.38, 24.34, 48.36, 45.82, 17.22, 24.47, 21.97, 22.34, 38.31, 32.02, 31.45, 36.3, 39.51, 16.7, 14.64, 38.33, 12.18, 45.25, 16.82, 22.57, 28.94, 26.27, 40.04, 24.83, 39.82, 11.66, 14.53, 23.78, 29.45, 34.81, 44.0, 19.79, 17.14, 18.22, 10.51, 10.87, 27.56, 25.49, 35.26, 15.21, 43.46, 10.94, 13.73, 28.58, 14.66, 14.45, 29.16, 37.91, 16.55, 12.86, 23.57, 42.82, 20.45, 33.85, 34.32, 20.73, 17.07, 18.31, 15.6, 32.48, 56.53, 17.95, 27.2, 38.02, 22.3, 19.47, 10.91, 12.92, 21.31, 41.33, 18.73, 12.07, 27.99, 35.34, 16.1, 29.83, 38.57, 11.96, 31.36, 38.44, 37.37, 16.53, 20.43, 32.81, 37.55, 12.49, 33.33, 18.57, 20.34, 48.8, 13.7, 11.73, 23.16, 11.29, 28.01, 12.96, 17.2, 41.44, 12.17, 21.42, 22.6, 41.91, 37.89, 35.59, 39.4, 31.69, 20.8, 42.02, 23.31, 19.61, 23.55, 21.7, 25.99, 38.41, 12.2, 37.02, 12.61, 10.21, 28.76, 29.24, 39.64, 36.84, 14.94, 19.97, 40.21, 36.67, 45.45, 12.42, 17.7, 42.04, 28.45, 36.43, 26.99, 27.18, 39.36, 12.05, 26.7, 41.01, 29.44, 30.16, 18.26, 16.25, 15.53, 25.92, 21.18, 10.29, 26.48, 27.6, 32.71, 26.88, 32.04, 40.89, 38.08, 25.96, 14.06, 27.1, 15.81, 49.53, 14.47, 14.03, 14.88, 16.26, 11.49, 17.33, 20.18, 15.46, 26.52, 14.39, 30.93, 31.74, 25.43, 10.08, 37.77, 14.0, 13.42, 36.4, 40.61, 44.81, 34.14, 35.23, 22.67, 10.19, 29.98, 15.15, 16.92, 24.54, 32.4, 27.4, 32.62, 38.96, 40.31, 23.38, 15.98, 19.16, 13.05, 37.38, 44.38, 12.28, 31.64, 30.77, 35.58, 21.72, 16.23, 28.68, 35.41, 23.18, 23.39, 32.65, 22.18, 24.73, 12.65, 15.2, 14.28, 16.66, 22.9, 33.92, 32.53, 14.19, 34.28, 40.33, 12.06, 13.25, 16.09, 19.01, 12.58, 13.69, 26.89, 24.0, 35.36, 30.99, 16.21, 11.83, 28.16, 19.49, 22.83, 33.58, 23.28, 15.92, 22.08, 38.97, 29.22, 26.55, 18.36, 34.68, 47.93, 43.48, 11.74, 18.44, 31.17, 30.37, 27.21, 21.06, 36.2, 20.05, 24.87, 17.77, 33.88, 39.94, 16.78, 16.14, 24.81, 14.05, 25.41, 24.07, 33.48, 29.21, 25.86, 17.11, 15.01, 11.06, 14.35, 32.58, 23.0, 33.42, 12.4, 16.73, 28.7, 29.12, 13.09, 11.67, 10.44, 25.29, 25.59, 14.92, 23.7, 43.79, 21.44, 16.97, 17.17, 26.15, 23.65, 26.22, 27.44, 15.14, 23.99, 15.58, 23.98, 26.42, 67.93, 12.45, 11.19, 33.01, 25.67, 36.51, 26.76, 15.35, 26.41, 34.34, 28.39, 21.71, 23.15, 24.13, 37.06, 22.37, 25.38, 21.02, 37.33, 29.73, 23.89, 11.57, 37.85, 28.06, 19.07, 21.52, 41.32, 16.0, 11.58, 14.09, 18.08, 70.82, 34.45, 36.6, 29.32, 37.4, 19.1, 14.62, 19.73, 30.58, 17.61, 28.23, 30.5, 29.07, 24.16, 35.37, 15.03, 23.91, 34.55, 39.27, 27.23, 12.8, 26.9, 37.7, 22.17, 14.27, 11.71, 35.67, 33.84, 33.36, 32.29, 34.48, 23.08, 20.91, 12.38, 27.47, 20.35, 29.64, 16.98, 18.4, 10.78, 16.12, 32.47, 31.16, 26.77, 31.86, 28.9, 23.33, 16.85, 11.41, 35.28, 13.95, 25.62, 34.84, 17.49, 41.15, 15.9, 35.7, 19.05, 14.72, 14.42, 26.64, 24.67, 23.92, 15.88, 29.69, 37.42, 29.48, 11.93, 12.95, 33.6, 35.97, 15.55, 28.71, 15.73, 40.12, 32.2, 24.05, 18.64, 19.15, 15.38, 33.76, 12.13, 32.84, 19.18, 18.34, 19.31, 23.37, 30.28, 20.07, 23.05, 13.63, 33.83, 15.69, 30.65, 27.06, 18.09, 31.92, 25.35, 39.43, 30.55, 10.2, 31.85, 35.44, 30.2, 14.99, 10.47, 19.44, 32.42, 13.23, 17.34, 34.38, 34.76, 36.12, 18.91, 34.08, 18.14, 16.32, 18.9, 17.48, 18.72, 25.44, 32.18, 25.81, 31.68, 25.82, 28.95, 10.95, 29.8, 13.48, 33.22, 35.54, 35.17, 17.26, 18.93, 17.82, 40.58, 16.65, 41.84, 11.6, 23.49, 22.26, 33.99, 32.01, 29.4, 29.26, 30.87, 40.16, 16.02, 24.04, 26.29, 34.72, 33.81, 17.63, 25.9, 31.41, 19.94, 27.0, 29.19, 27.62, 28.21, 21.4, 35.96, 50.29, 11.95, 16.4, 10.8, 12.35, 16.17, 16.62, 30.31, 14.51, 36.56, 36.75, 26.91, 21.54, 31.0, 38.06, 18.13, 23.74, 25.27, 12.1, 38.91, 21.48, 12.9, 22.21, 18.81, 26.85, 19.67, 18.69, 10.45, 25.83, 18.53, 13.02, 23.5, 27.28, 25.78, 15.4, 24.71, 27.91, 22.28, 31.2, 21.81, 15.94, 10.33, 33.56, 15.79, 12.88, 13.99, 19.86, 20.93, 15.31, 15.78, 34.57, 12.55, 24.64, 14.76, 21.98, 18.8, 16.48, 24.19, 25.17, 27.98, 37.79, 14.3, 14.17, 13.08, 24.38, 21.32, 21.93, 25.15, 31.18, 29.39, 18.23, 25.32, 17.92, 25.52, 13.56, 23.46, 20.67, 25.16, 17.68, 26.09, 31.12, 19.6, 39.52, 24.33, 11.55, 17.27, 10.68, 14.12, 23.19, 36.27, 19.92, 19.88, 19.69, 11.8, 25.65, 10.74, 22.63, 20.76, 26.02, 16.08, 19.71, 28.31, 17.35, 24.93, 22.98, 27.11, 43.23, 14.82, 27.85, 25.01, 35.42, 35.33, 33.43, 15.32, 14.16, 27.96, 31.42, 23.69, 30.82, 13.59, 17.15, 13.41, 10.62, 22.55, 43.24, 18.18, 26.69, 17.97, 27.05, 12.48, 17.96, 18.16, 11.27, 21.28, 25.42, 36.41, 16.43, 11.94, 12.81, 44.04, 48.53, 11.36, 22.81, 12.83, 19.14, 28.59, 30.85, 13.64, 19.91, 27.29, 22.72, 37.63, 45.61, 18.27, 13.71, 36.54, 34.1, 28.02, 30.36, 25.04, 13.88, 28.41, 17.06, 27.38, 13.45, 15.07, 24.79, 23.29, 12.69, 13.62, 51.38, 36.28, 11.23, 11.35, 18.33, 18.71, 15.82, 30.08, 38.38, 31.6, 10.5, 16.87, 14.68, 17.98, 37.07, 25.58, 21.05, 17.42, 18.78, 24.43, 24.77, 11.12, 19.29, 34.12, 32.66, 20.78, 17.12, 22.89, 22.69, 40.36, 14.89, 22.65, 16.07, 29.41, 12.7, 29.66, 25.95, 29.33, 37.86, 30.02, 35.94, 22.88, 13.98, 20.71, 16.44, 16.99, 19.42, 32.67, 37.75, 22.13, 12.03, 19.81, 31.24, 13.01, 32.89, 19.77, 18.56, 17.6, 11.37, 16.36, 14.32, 10.86, 22.93, 37.19, 36.83, 13.68, 36.25, 27.72, 30.3, 33.54, 32.1, 14.11, 23.41, 35.46, 27.63, 15.99, 10.03, 37.08, 28.4, 33.86, 20.4, 25.0, 22.33, 29.7, 27.57, 28.69, 38.54, 29.46, 23.52, 36.0, 39.53, 23.61, 26.35, 10.27, 28.8, 39.12, 33.91, 23.68, 10.39, 17.19, 20.38, 23.75, 33.64, 18.2, 39.21, 19.76, 22.95, 26.65, 26.12, 27.36, 11.56, 23.13, 11.48, 13.57, 21.19, 41.42, 19.19, 39.91, 22.23, 36.87, 29.04, 11.07, 31.67, 24.74, 20.85, 34.35, 31.62, 28.82, 18.96, 34.6, 23.1, 19.39, 27.16, 29.34, 34.64, 21.47, 35.47, 30.47, 26.86, 33.15, 11.65, 31.39, 14.33, 18.38, 35.49, 12.59, 33.21, 28.15, 55.0, 29.15, 16.71, 26.8, 30.83, 39.8, 15.0, 43.09, 29.63, 43.41, 26.14, 13.38, 21.14, 42.18, 36.44, 15.7, 28.48, 14.65, 29.92, 25.87, 15.05, 20.96, 36.19, 27.9, 34.16, 11.21, 28.08, 31.33, 38.23, 24.06, 26.71, 17.05, 23.02, 26.33, 33.24, 33.45, 25.54, 13.03, 15.77, 25.57, 43.52, 36.02, 15.64, 13.04, 48.14, 29.06, 34.25, 17.13, 23.04, 36.09, 18.89, 33.02, 13.76, 29.75, 10.54, 17.83, 37.66, 39.18, 28.14, 41.85, 39.35, 36.22, 18.63, 29.31, 22.49, 10.89, 35.95, 33.69, 32.55, 12.16, 13.32, 15.11, 12.67, 40.65, 16.33, 23.67, 39.07, 44.85, 21.74, 41.37, 45.71, 15.36, 10.73, 36.8, 47.97, 41.73, 32.5, 33.57, 32.12, 29.55, 30.05, 26.24, 20.26, 39.45, 26.45, 12.41, 39.14, 29.84, 43.56, 41.0, 18.87, 24.95, 12.68, 29.85, 14.26, 24.65, 20.0, 38.58, 24.5, 13.89, 20.92, 35.76, 46.35, 44.54, 11.28, 29.86, 22.82, 41.63, 42.72, 28.09, 24.52, 36.76, 33.82, 30.62, 36.35, 27.89, 23.3, 18.97, 13.92, 11.9, 20.88, 29.74, 11.15, 13.31, 19.7, 15.61, 27.78, 17.21, 32.24, 20.13, 11.0, 28.29, 18.66, 28.78, 11.33, 10.38, 17.04, 17.66, 21.2, 16.16, 19.68, 40.55, 22.64, 40.57, 24.1, 18.55, 24.14, 23.59, 33.8, 32.79, 38.22, 30.67, 26.34, 29.01, 19.55, 18.85, 10.01, 31.43, 35.99, 30.76, 33.7, 37.32, 24.7, 20.75, 19.35, 24.97, 12.11, 28.53, 10.17, 31.29, 25.6, 34.95, 41.72, 30.43, 18.06, 29.97, 16.51, 10.11, 40.76, 43.34, 21.1, 11.3, 35.05, 27.75, 34.46, 11.46, 12.89, 39.72, 29.61, 35.89, 39.66, 18.04, 28.88, 18.52, 18.01, 13.8, 37.27, 26.13, 22.77, 15.47, 48.12, 12.02, 31.99, 29.08, 44.19, 36.78, 21.46, 10.41, 10.07, 38.12, 13.55, 32.95, 22.11, 16.04, 32.38, 17.74, 19.78, 23.03, 20.25, 10.55, 32.35, 38.1, 32.57, 31.27, 27.69, 16.03, 22.56, 50.96, 30.64, 34.51, 34.26, 10.37, 12.22, 37.44, 33.03, 10.42, 14.23, 31.66, 40.67, 15.44, 31.23, 30.19, 11.04, 11.17, 24.82, 23.27, 40.53, 40.3, 36.47, 13.44, 32.77, 45.78, 12.46, 24.56, 36.82, 16.54, 17.5, 31.75, 24.69, 31.1, 24.51, 19.85, 11.7, 19.58, 19.26, 19.62, 18.28, 36.99, 10.56, 21.94, 20.23, 13.17, 22.16, 26.68, 32.78, 37.24, 28.11, 45.2, 26.03, 24.45, 22.22, 13.19, 18.02, 11.02, 21.23, 26.06, 13.75, 37.46, 38.99, 25.06, 32.43, 19.87, 39.88, 21.34, 22.84, 24.12, 47.85, 18.67, 15.96, 14.71, 39.03, 19.04, 18.95, 40.06, 24.31, 36.62, 17.71, 12.12, 30.35, 38.59, 14.5, 38.39, 34.06, 27.48, 18.45, 25.22, 28.12, 10.23, 36.58, 28.87, 33.11, 37.76, 37.2, 40.19, 14.79, 35.3, 11.26, 34.18, 16.72, 21.78, 16.3, 40.52, 21.21, 18.5, 29.71, 21.39, 10.05, 35.4, 35.84, 16.29, 16.06, 34.0, 14.24, 30.72, 10.12, 28.44, 39.65, 12.32, 30.61, 33.05, 37.25, 17.59, 31.06, 38.89, 37.74, 15.22, 30.25, 30.81, 11.98, 28.61, 12.14, 42.23, 15.34, 12.73, 26.18, 36.96, 24.01, 29.02, 27.12, 29.2, 29.68, 10.52, 30.92, 27.64, 26.25, 22.45, 29.59, 38.77, 27.3, 25.68, 14.84, 35.51, 25.39, 15.51, 37.18, 28.36, 19.53, 37.05, 20.82, 30.45, 29.1, 25.73, 11.53, 23.88, 29.09, 32.61, 26.23, 15.48, 11.25, 24.39, 22.61, 35.14, 36.14, 30.06, 18.65, 20.27, 29.58, 15.43, 23.93, 21.92, 10.49, 30.86, 36.06, 35.77, 26.07, 29.9, 40.01, 32.74, 24.58, 38.65, 27.42, 24.92, 15.8, 36.53, 31.65, 17.9, 35.56, 41.36, 37.04, 28.32, 12.63, 28.75, 33.75, 37.45, 28.89, 31.31, 33.53, 39.56, 36.98, 31.07, 33.52, 36.7, 42.56, 27.04, 26.01, 29.56, 10.97, 20.01, 30.46, 16.24, 23.62, 26.84, 24.11, 20.64, 30.63, 22.31, 25.74, 34.75, 29.76, 25.66, 29.23, 30.14, 31.87, 12.91, 34.15, 41.08, 27.88, 17.41, 15.28, 18.88, 24.2, 28.27, 22.27, 27.37, 10.06, 21.69, 29.65, 30.12, 34.78, 23.85, 11.32, 11.31, 28.47, 28.42, 16.75, 18.42, 28.77, 34.92, 34.62, 35.53, 27.39, 21.35, 11.69, 38.84, 31.28, 32.16, 41.53, 39.86, 59.82, 24.75, 33.59, 29.25, 44.45, 17.18, 27.43, 34.63, 48.76, 23.06, 38.07, 38.48, 26.75, 38.04, 27.92, 21.85, 53.06, 11.84, 11.64, 31.46, 28.79, 16.96, 20.14, 26.6, 38.55, 42.36, 14.4, 42.78, 40.79, 35.55, 30.79, 38.5, 38.09, 27.53, 35.65, 24.85, 33.35, 16.69, 26.26, 56.48, 30.33, 24.23, 30.9, 30.57, 16.68, 40.07, 34.33, 33.94, 26.67, 37.72, 31.79, 30.89, 29.35, 12.57, 10.28, 28.07, 18.1, 28.74, 33.66, 26.19, 17.53, 32.52, 24.66, 37.17, 20.97, 21.51, 20.02, 54.05, 37.53, 28.72, 13.39, 27.73, 33.26, 31.63, 25.55, 27.24, 25.45, 25.47, 22.48, 12.64, 30.94, 28.56, 12.76, 28.63, 27.71, 44.35, 27.27, 13.3, 36.85, 24.68, 10.4, 35.27, 14.98, 12.98, 16.18, 27.41, 26.17, 29.51, 24.76, 25.03, 10.53, 44.92, 41.75, 41.1, 24.18, 47.49, 20.39, 27.26, 32.87, 28.46, 32.73, 16.41, 30.96, 15.67, 26.73, 17.65, 38.3, 40.74, 32.99, 34.56, 34.8, 36.65, 31.96, 11.05, 35.66, 41.74, 44.62, 32.34, 37.39, 34.54, 11.1, 34.83, 12.74, 37.96, 42.08, 30.01, 34.9, 30.1, 22.74, 17.52, 40.13, 35.91, 31.58, 39.67, 12.09, 30.21, 21.03, 27.83, 24.36, 38.03, 15.26, 28.6, 36.42, 36.39, 27.54, 38.71, 33.65, 35.12, 34.02, 31.61, 31.71, 10.16, 32.92, 10.92, 29.94, 28.64, 19.54, 33.72, 32.91, 39.39, 33.44, 28.54, 31.11, 27.81, 34.58, 19.57, 33.18, 20.15, 28.05, 29.27, 32.14, 32.31, 36.91, 32.63, 41.31, 28.33, 13.46, 35.48, 33.31, 34.42, 36.01, 16.74, 42.22, 39.89, 18.82, 36.03, 33.13, 34.74, 25.91, 33.96, 40.14, 31.37, 28.96, 33.06, 30.26, 41.5, 33.3, 22.25, 31.35, 11.09, 28.34, 12.51, 24.21, 26.32, 38.56, 38.11, 33.16, 29.42, 62.6, 18.54, 27.77, 29.38, 25.97, 36.29, 35.52, 48.22, 37.83, 41.14, 37.31, 38.69, 42.29, 31.84, 31.55, 27.7, 29.79, 34.07, 34.79, 39.42, 35.25, 46.24, 34.71, 26.94, 32.96, 30.52, 37.54, 56.71, 24.8, 41.49, 58.01, 19.66, 37.21, 35.2, 42.06, 27.87, 29.29, 28.91, 32.82, 39.73, 58.57, 26.37, 29.88, 24.78, 23.8, 29.14, 48.93, 40.17, 42.94, 11.42, 11.16, 43.03, 33.95, 10.9, 29.49, 42.98, 13.97, 18.32, 46.76, 45.58, 34.91, 36.64, 46.25, 48.2, 37.03, 31.51, 34.37, 38.76, 28.49, 13.43, 40.84, 36.73, 10.26, 30.18, 27.66, 29.81, 32.33, 11.11, 22.59, 14.85, 34.4, 24.9, 37.34, 38.95, 21.16, 40.24, 11.24, 20.81, 32.11, 33.41, 12.08, 37.48, 45.37, 36.72, 41.12, 31.81, 45.77, 48.62, 45.05, 20.61, 35.64, 16.05, 33.61, 43.14, 27.79, 28.3, 47.62, 47.37, 35.88, 59.79, 49.88, 45.31, 52.28, 28.22, 46.01, 45.87, 29.89, 38.8, 48.42, 47.1, 32.94, 40.66, 25.12, 24.25, 60.29, 24.94, 19.52, 45.22, 56.85, 28.67, 38.61, 43.82, 44.08, 39.81, 29.0, 45.75, 46.89, 39.11, 38.62, 51.31, 39.79, 39.01, 47.33, 49.65, 47.63, 36.11, 31.59, 44.53, 35.13, 32.19, 27.51, 13.9, 36.63, 34.88, 38.53, 34.01, 38.35, 24.91, 25.02, 10.02, 39.33, 30.23, 29.03, 30.54, 43.86, 29.18, 39.71, 27.84, 33.1, 32.28, 34.31, 30.78, 26.51, 37.57, 38.94, 30.75, 32.23, 10.71, 41.62, 32.85, 46.14, 36.81, 32.54, 35.68, 31.21, 25.34, 40.02, 32.37, 36.59, 26.78, 30.8, 38.13, 28.28, 23.42, 47.55, 31.82, 40.82, 54.46, 38.4, 27.45, 27.52, 35.72, 29.05, 39.37, 49.85, 43.13, 48.59, 48.74, 42.74, 19.02, 33.32, 37.0, 46.79, 48.4, 37.69, 46.73, 42.42, 39.6, 49.35, 36.61, 24.32, 43.22, 43.57, 39.97, 50.2, 43.47, 48.48, 47.7, 48.17, 49.51, 43.45, 46.37, 44.73, 37.78, 43.12, 40.8, 37.93, 46.57, 49.76, 40.38, 40.43, 45.6, 40.46, 42.27, 43.9, 43.49, 44.55, 26.46, 45.86, 42.89, 37.87, 37.6, 49.12, 30.98, 41.21, 38.7, 52.58, 37.98, 41.67, 37.41, 33.98, 10.84, 28.65, 49.66, 48.13, 65.8, 34.97, 36.48, 31.05, 47.96, 45.5, 11.44, 66.81, 43.18, 38.85, 35.32, 39.49, 26.57, 10.14, 53.76, 36.9, 44.64, 37.71, 31.38, 46.49, 42.99, 63.29, 36.21, 35.98, 36.74, 46.07, 44.05, 40.35, 40.92, 22.96, 35.06, 46.05, 40.05, 41.65, 34.03, 39.28, 48.06, 11.2, 23.71, 35.19, 10.76, 26.96, 42.0, 31.7, 33.51, 31.25, 40.34, 39.26, 51.98, 33.2, 32.27, 37.14, 39.58, 49.47, 44.15, 32.15, 40.72, 35.38, 31.95, 32.45, 33.25, 26.2, 36.69, 65.3, 38.93, 36.37, 40.1, 28.99, 44.11, 41.43, 41.13, 39.05, 13.51, 33.63, 24.61, 20.69, 32.49, 39.34, 20.57, 16.84, 20.12, 28.62, 11.22, 44.57, 34.87, 32.36, 20.49, 33.55, 14.36, 23.36, 38.6, 11.75, 26.36, 35.31, 34.59, 35.74, 40.48, 36.31, 39.38, 13.06, 40.26, 51.08, 21.56, 26.44, 28.52, 39.02, 28.98, 34.39, 25.71, 12.15, 33.19, 32.17, 41.71, 30.41, 35.87, 29.43, 21.12, 27.82, 44.66, 42.01, 40.94, 32.41, 41.23, 37.73, 33.77, 27.74, 20.33, 25.72, 19.59, 34.65, 24.08, 41.02, 32.64, 39.48, 38.9, 28.97, 39.61, 10.31, 35.63, 39.55, 42.7, 36.17, 49.14, 38.24, 31.08, 77.97, 37.13, 48.65, 32.86, 45.21, 47.42, 47.23, 30.11, 42.54, 45.92, 36.5, 34.05, 43.87, 43.67, 30.07, 38.72, 42.4, 10.82, 43.68, 38.66, 51.0, 42.31, 49.83, 69.9, 38.88, 33.68, 34.23, 37.51, 43.19, 59.24, 27.67, 40.71, 32.06, 60.82, 35.6, 34.69, 26.98, 40.28, 37.23, 27.15, 37.01, 39.0, 27.01, 34.85, 38.21, 48.11, 28.57, 31.83, 32.32, 25.51, 37.8, 38.25, 31.9, 33.09, 34.49, 39.59, 34.21, 35.16, 49.61, 32.56, 33.71, 23.09, 27.22, 27.76, 46.91, 43.31, 39.63, 34.82, 43.61, 38.68, 42.32, 32.75, 69.97, 37.28, 38.51, 31.93, 56.32, 60.3, 39.22, 30.04, 41.46, 28.13, 34.89, 32.59, 37.47, 43.35, 38.29, 29.78, 37.61, 38.79, 48.6, 40.93, 33.67, 35.93, 39.83, 38.98, 40.62, 46.59, 39.7, 39.96, 15.33, 73.01, 45.14, 29.36, 32.13, 55.65, 51.72, 43.54, 26.47, 32.7, 35.73, 39.69, 35.24, 38.81, 40.96, 30.13, 32.6, 34.29, 36.24, 43.3, 39.3, 41.4, 35.21, 47.94, 38.18, 35.61, 54.35, 34.66, 39.84, 44.32, 33.0, 26.05, 52.12, 40.27, 40.97, 37.15, 35.02, 38.05, 26.21, 46.33, 17.47, 47.43, 39.68, 40.49, 31.78, 42.87, 12.23, 43.01, 42.43, 37.22, 41.34, 38.75, 21.3, 27.25, 41.98, 28.92, 37.99, 31.32, 50.76, 36.36, 30.88, 44.77, 29.95, 47.47, 42.05, 35.07, 35.1, 29.67, 38.2, 43.89, 41.93, 41.2, 34.98, 41.17, 29.77, 36.38, 41.18, 39.31, 38.27, 33.73, 38.64, 40.32, 37.56, 34.53, 26.38, 39.98, 36.1, 37.3, 31.56, 31.77, 37.11, 40.63, 42.51, 22.47, 43.95, 39.44, 19.98, 30.7, 26.3, 42.16, 32.26, 44.27, 31.8, 38.01, 38.47, 37.68, 37.43, 36.79, 24.98, 47.34, 40.09, 40.47, 46.32, 44.21, 50.77, 48.52, 34.73, 42.65, 42.66, 47.44, 48.39, 38.43, 45.65, 45.34, 44.02, 48.3, 36.05, 39.09, 50.06, 47.08, 46.67, 45.43, 44.6, 45.53, 41.03, 36.71, 39.46, 45.63, 30.95, 26.59, 43.43, 40.37, 44.69, 40.88, 43.26, 51.44, 37.67, 51.32, 40.77, 40.0, 49.04, 49.63, 35.9, 56.66, 49.99, 37.9, 47.02, 42.67, 44.76, 49.57, 47.48, 47.9, 44.83, 38.74, 49.36, 37.49, 42.03, 47.17, 49.74, 34.09, 37.82, 41.82, 36.52, 49.3, 50.07, 48.15, 36.13, 39.57, 50.88, 49.26, 45.29, 42.76, 37.97, 38.32, 39.1, 27.97, 30.56, 33.79, 40.95, 34.94, 46.5, 36.23, 38.82, 31.72, 48.68, 25.37, 29.37, 39.76, 34.96, 35.03, 39.47, 42.09, 52.29, 46.6, 45.41, 38.83, 50.3, 40.59, 44.78, \n",
      "===================================================\n",
      "\n",
      "Column: origin_lat\n",
      "Unique values:\n",
      "35.625, 36.0, 35.68, 35.745, 35.705, 35.815, 35.75, 35.65, 35.675, 35.69, 35.785, 35.995, 35.875, 35.5, 35.805, 35.95, 35.575, 35.505, 35.56, 35.51, 35.565, 35.54, 35.52, 35.91, 35.735, 35.76, 35.55, 35.82, 35.765, 35.945, 35.7, 35.97, 35.865, 35.74, 35.955, 35.725, 35.8, 35.525, 35.98, 35.62, 35.81, 35.635, 35.975, 35.89, 35.615, 35.59, 35.535, 35.77, 35.555, 35.84, 35.845, 35.64, 35.595, 35.99, 35.775, 35.53, 35.855, 35.71, 35.545, 35.9, 35.93, 35.905, 35.825, 35.83, \n",
      "===================================================\n",
      "\n",
      "Column: origin_long\n",
      "Unique values:\n",
      "51.375, 51.085, 51.445, 51.465, 51.295, 51.32, 51.385, 51.31, 51.37, 51.24, 51.0, 51.045, 51.275, 51.315, 51.5, 51.345, 51.185, 51.42, 51.18, 51.415, 51.155, 51.06, 51.285, 51.19, 51.4, 51.225, 51.075, 51.17, 51.115, 51.25, 51.135, 51.215, 51.025, 51.26, 51.2, 51.195, 51.12, 51.245, 51.15, 51.3, 51.1, 51.05, 51.47, 51.435, 51.46, 51.125, 51.21, 51.175, 51.305, 51.28, 51.13, 51.165, 51.235, 51.27, 51.475, 51.39, 51.485, 51.09, 51.29, 51.145, 51.095, 51.495, 51.11, 51.035, 51.35, \n",
      "===================================================\n",
      "\n",
      "Column: dest_lat\n",
      "Unique values:\n",
      "36.0, 35.625, 35.745, 35.68, 35.75, 35.65, 35.675, 35.69, 35.785, 35.875, 35.5, 35.805, 35.815, 35.95, 35.52, 35.505, 35.56, 35.51, 35.565, 35.54, 35.91, 35.995, 35.55, 35.735, 35.705, 35.82, 35.76, 35.765, 35.945, 35.575, 35.7, 35.59, 35.97, 35.865, 35.74, 35.955, 35.725, 35.8, 35.525, 35.98, 35.62, 35.81, 35.975, 35.635, 35.89, 35.615, 35.535, 35.77, 35.555, 35.84, 35.845, 35.64, 35.595, 35.99, 35.775, 35.53, 35.855, 35.71, 35.545, 35.9, 35.93, 35.905, 35.825, 35.83, \n",
      "===================================================\n",
      "\n",
      "Column: dest_long\n",
      "Unique values:\n",
      "51.085, 51.375, 51.465, 51.445, 51.385, 51.31, 51.37, 51.295, 51.24, 51.045, 51.275, 51.5, 51.345, 51.315, 51.185, 51.285, 51.32, 51.18, 51.415, 51.155, 51.06, 51.19, 51.0, 51.225, 51.4, 51.075, 51.17, 51.42, 51.25, 51.115, 51.135, 51.47, 51.215, 51.025, 51.26, 51.2, 51.195, 51.12, 51.245, 51.3, 51.1, 51.05, 51.15, 51.435, 51.46, 51.125, 51.21, 51.175, 51.305, 51.28, 51.13, 51.165, 51.235, 51.27, 51.475, 51.39, 51.485, 51.09, 51.29, 51.145, 51.095, 51.495, 51.11, 51.035, 51.35, \n",
      "===================================================\n",
      "\n",
      "Column: dest\n",
      "Unique values:\n",
      "restaurant, work, home, park, university, gym, pool, \n",
      "===================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out the unique values for each column\n",
    "# TODO\n",
    "for column in data.columns:\n",
    "    print(f'Column: {column}')\n",
    "    print(f'Unique values:')\n",
    "    for value in data[column].unique():\n",
    "        print(value, end=', ')\n",
    "    print('\\n===================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: user_id\n",
      "Data type: int64\n",
      "===================================================\n",
      "\n",
      "Column: Day\n",
      "Data type: int64\n",
      "===================================================\n",
      "\n",
      "Column: origin\n",
      "Data type: object\n",
      "===================================================\n",
      "\n",
      "Column: start_time\n",
      "Data type: object\n",
      "===================================================\n",
      "\n",
      "Column: end_time\n",
      "Data type: object\n",
      "===================================================\n",
      "\n",
      "Column: price\n",
      "Data type: float64\n",
      "===================================================\n",
      "\n",
      "Column: origin_lat\n",
      "Data type: float64\n",
      "===================================================\n",
      "\n",
      "Column: origin_long\n",
      "Data type: float64\n",
      "===================================================\n",
      "\n",
      "Column: dest_lat\n",
      "Data type: float64\n",
      "===================================================\n",
      "\n",
      "Column: dest_long\n",
      "Data type: float64\n",
      "===================================================\n",
      "\n",
      "Column: dest\n",
      "Data type: object\n",
      "===================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out the data type of each column\n",
    "# TODO\n",
    "for column in data.columns:\n",
    "    print(f'Column: {column}')\n",
    "    print(f'Data type: {data[column].dtype}')\n",
    "    print('===================================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your features and how you extracted them, you may need to use some encodings for your data. For example, if you have different classes as names (`str` data type. E.g. \"gym\") you need to make it a numeric value in order to feed it into your neural network. You can use `sklearn`'s functions (such as `LabelEncoder`, `OneHotEncoder`, `StandardScaler`, etc.) to do these kind of stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3d/rywrw2f90d13m9fcnt9sf1gw0000gn/T/ipykernel_14526/1458358166.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['start_time'] = pd.to_datetime(data['start_time']).astype(int)\n",
      "/var/folders/3d/rywrw2f90d13m9fcnt9sf1gw0000gn/T/ipykernel_14526/1458358166.py:36: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['end_time'] = pd.to_datetime(data['end_time']).astype(int)\n",
      "/var/folders/3d/rywrw2f90d13m9fcnt9sf1gw0000gn/T/ipykernel_14526/1458358166.py:37: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  test_data['start_time'] = pd.to_datetime(test_data['start_time']).astype(int)\n",
      "/var/folders/3d/rywrw2f90d13m9fcnt9sf1gw0000gn/T/ipykernel_14526/1458358166.py:38: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  test_data['end_time'] = pd.to_datetime(test_data['end_time']).astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Finalize the data (do all preprocessing needed)\n",
    "# TODO\n",
    "\n",
    "# Make user_id one-hot encoded\n",
    "user_id_encoder = OneHotEncoder()\n",
    "user_id_encoder.fit(data[['user_id']])\n",
    "user_id_encoded = user_id_encoder.transform(data[['user_id']]).toarray()\n",
    "user_id_encoded = pd.DataFrame(user_id_encoded, columns=user_id_encoder.categories_[0])\n",
    "data = pd.concat([data, user_id_encoded], axis=1)\n",
    "data = data.drop(['user_id'], axis=1)\n",
    "test_user_id_encoded = user_id_encoder.transform(test_data[['user_id']]).toarray()\n",
    "test_user_id_encoded = pd.DataFrame(test_user_id_encoded, columns=user_id_encoder.categories_[0])\n",
    "test_data = pd.concat([test_data, test_user_id_encoded], axis=1)\n",
    "test_data = test_data.drop(['user_id'], axis=1)\n",
    "\n",
    "\n",
    "# Make origin one-hot encoded\n",
    "origin_encoder = OneHotEncoder()\n",
    "origin_encoder.fit(data[['origin']])\n",
    "origin_encoded = origin_encoder.transform(data[['origin']]).toarray()\n",
    "origin_encoded = pd.DataFrame(origin_encoded, columns=origin_encoder.categories_[0])\n",
    "data = pd.concat([data, origin_encoded], axis=1)\n",
    "data = data.drop(['origin'], axis=1)\n",
    "test_origin_encoded = origin_encoder.transform(test_data[['origin']]).toarray()\n",
    "test_origin_encoded = pd.DataFrame(test_origin_encoded, columns=origin_encoder.categories_[0])\n",
    "test_data = pd.concat([test_data, test_origin_encoded], axis=1)\n",
    "test_data = test_data.drop(['origin'], axis=1)\n",
    "\n",
    "\n",
    "# Standardize Day, start_time, end_time, price, origin_lat, origin_long, dest_lat, dest_long\n",
    "data['start_time'] = pd.to_datetime(data['start_time']).astype(int)\n",
    "data['end_time'] = pd.to_datetime(data['end_time']).astype(int)\n",
    "test_data['start_time'] = pd.to_datetime(test_data['start_time']).astype(int)\n",
    "test_data['end_time'] = pd.to_datetime(test_data['end_time']).astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data[['Day', 'start_time', 'end_time', 'price', 'origin_lat', 'origin_long', 'dest_lat', 'dest_long']] = scaler.fit_transform(data[['Day', 'start_time', 'end_time', 'price', 'origin_lat', 'origin_long', 'dest_lat', 'dest_long']])\n",
    "test_data[['Day', 'start_time', 'end_time', 'price', 'origin_lat', 'origin_long', 'dest_lat', 'dest_long']] = scaler.transform(test_data[['Day', 'start_time', 'end_time', 'price', 'origin_lat', 'origin_long', 'dest_lat', 'dest_long']])\n",
    "data.head()\n",
    "\n",
    "\n",
    "# train - validation - test split\n",
    "train, val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "test = test_data\n",
    "\n",
    "\n",
    "# separating inputs and outputs\n",
    "x_train = train.drop(['dest'], axis=1)\n",
    "y_train = train[['dest']]\n",
    "x_val = val.drop(['dest'], axis=1)\n",
    "y_val = val[['dest']]\n",
    "x_test = test.drop(['dest'], axis=1)\n",
    "y_test = test[['dest']]\n",
    "\n",
    "\n",
    "# droping dest_lat and dest_long from input cause it's kind of cheating\n",
    "x_train = x_train.drop(['dest_lat', 'dest_long'], axis=1)\n",
    "x_val = x_val.drop(['dest_lat', 'dest_long'], axis=1)\n",
    "x_test = x_test.drop(['dest_lat', 'dest_long'], axis=1)\n",
    "\n",
    "\n",
    "# encoding dest\n",
    "dest_dict = {dest:i for i, dest in enumerate(data['dest'].unique())}\n",
    "y_train = y_train.replace(dest_dict)\n",
    "y_val = y_val.replace(dest_dict)\n",
    "y_test = y_test.replace(dest_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "torch.Size([14395, 73])\n",
      "torch.Size([14395, 1])\n",
      "torch.Size([3599, 73])\n",
      "torch.Size([3599, 1])\n",
      "torch.Size([4499, 73])\n",
      "torch.Size([4499, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "\n",
    "x_train = torch.tensor(x_train.values, device=device, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train.values, device=device, dtype=torch.int)\n",
    "x_val = torch.tensor(x_val.values, device=device, dtype=torch.float)\n",
    "y_val = torch.tensor(y_val.values, device=device, dtype=torch.int)\n",
    "x_test = torch.tensor(x_test.values, device=device, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test.values, device=device, dtype=torch.int)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `train_dataset` and its loader, also create `test_dataset` and its loader. You should also create `val_dataset` and its loader if you want to use validation set. You may need to implement a custom `torch.Dataset` class for your ease. Your loaders should be able to load data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# TODO\n",
    "train_dataset = list(zip(x_train, y_train))\n",
    "val_dataset = list(zip(x_val, y_val))\n",
    "test_dataset = list(zip(x_test, y_test))\n",
    "\n",
    "# Batch size\n",
    "batch_size = 2**10\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you should implement your neural network model. You should use `pytorch`. **Note** that you should plot the loss function of your model during the training phase. (on both training and validation sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the train_model function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    # TODO\n",
    "    # training loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            y = y.squeeze()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        for x, y in val_loader:\n",
    "            output = model(x)\n",
    "            y = y.squeeze()\n",
    "            loss = criterion(output, y)\n",
    "            val_loss += loss.item() * x.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        if val_loss == min(val_losses):\n",
    "            torch.save(model.state_dict(), \"mlp.pth\")\n",
    "        print(f'Epoch: {epoch+1}/{epochs}\\t|\\tTrain loss: {train_loss}\\t|\\tVal loss: {val_loss}')\n",
    "    \n",
    "    # TODO\n",
    "    # Plot training and validation losses\n",
    "    plt.plot(train_losses, label='train loss')\n",
    "    plt.plot(val_losses, label='val loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Implement the MLP class with your choice of architecture\n",
    "# TODO: You can change the signature of functions and also add any function you need\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=7, dropout=0.1):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(64, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Define Model, Loss, Optimizer\n",
    "model = MLP(input_dim=len(x_train[0]), output_dim=7, dropout=0.0).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\t|\tTrain loss: 1.6866440534343237\t|\tVal loss: 1.288236054422856\n",
      "Epoch: 2/100\t|\tTrain loss: 1.1867167785872432\t|\tVal loss: 1.0026282667285635\n",
      "Epoch: 3/100\t|\tTrain loss: 0.9046896729174485\t|\tVal loss: 0.7350905949488452\n",
      "Epoch: 4/100\t|\tTrain loss: 0.6749966841101771\t|\tVal loss: 0.5752154075956968\n",
      "Epoch: 5/100\t|\tTrain loss: 0.5426638621056648\t|\tVal loss: 0.47349306193283114\n",
      "Epoch: 6/100\t|\tTrain loss: 0.4389331562211009\t|\tVal loss: 0.3780101951575008\n",
      "Epoch: 7/100\t|\tTrain loss: 0.35963343789528623\t|\tVal loss: 0.32161327462853506\n",
      "Epoch: 8/100\t|\tTrain loss: 0.3119870028569492\t|\tVal loss: 0.29205272024821893\n",
      "Epoch: 9/100\t|\tTrain loss: 0.285002588376936\t|\tVal loss: 0.27095571338352015\n",
      "Epoch: 10/100\t|\tTrain loss: 0.2633433115631394\t|\tVal loss: 0.25526963440568357\n",
      "Epoch: 11/100\t|\tTrain loss: 0.2461303125822366\t|\tVal loss: 0.24242540716164376\n",
      "Epoch: 12/100\t|\tTrain loss: 0.23228290436602417\t|\tVal loss: 0.24049208169349137\n",
      "Epoch: 13/100\t|\tTrain loss: 0.22139721300586224\t|\tVal loss: 0.22689705097566018\n",
      "Epoch: 14/100\t|\tTrain loss: 0.2145524057239739\t|\tVal loss: 0.2123566054410158\n",
      "Epoch: 15/100\t|\tTrain loss: 0.20135861163691707\t|\tVal loss: 0.21037800783960645\n",
      "Epoch: 16/100\t|\tTrain loss: 0.19523747194637314\t|\tVal loss: 0.1985853955327686\n",
      "Epoch: 17/100\t|\tTrain loss: 0.18593991782442484\t|\tVal loss: 0.2025638122042208\n",
      "Epoch: 18/100\t|\tTrain loss: 0.18676359872099177\t|\tVal loss: 0.19302397415716802\n",
      "Epoch: 19/100\t|\tTrain loss: 0.180126948672767\t|\tVal loss: 0.1851082441416937\n",
      "Epoch: 20/100\t|\tTrain loss: 0.16864782520138005\t|\tVal loss: 0.17981422186792145\n",
      "Epoch: 21/100\t|\tTrain loss: 0.1647363737706883\t|\tVal loss: 0.1799594791490656\n",
      "Epoch: 22/100\t|\tTrain loss: 0.15884882608876952\t|\tVal loss: 0.17103426522780008\n",
      "Epoch: 23/100\t|\tTrain loss: 0.15375036738862094\t|\tVal loss: 0.17211490578040642\n",
      "Epoch: 24/100\t|\tTrain loss: 0.15072806005202138\t|\tVal loss: 0.16833430380001768\n",
      "Epoch: 25/100\t|\tTrain loss: 0.1475947582191707\t|\tVal loss: 0.16111955993554433\n",
      "Epoch: 26/100\t|\tTrain loss: 0.14406879419210514\t|\tVal loss: 0.16337439524246342\n",
      "Epoch: 27/100\t|\tTrain loss: 0.1417709818106635\t|\tVal loss: 0.15913552521549684\n",
      "Epoch: 28/100\t|\tTrain loss: 0.13915598859344766\t|\tVal loss: 0.16127934316175785\n",
      "Epoch: 29/100\t|\tTrain loss: 0.14447157826946194\t|\tVal loss: 0.15465071587868617\n",
      "Epoch: 30/100\t|\tTrain loss: 0.1338953722430087\t|\tVal loss: 0.14739428096660212\n",
      "Epoch: 31/100\t|\tTrain loss: 0.12915208906494274\t|\tVal loss: 0.14639846886999575\n",
      "Epoch: 32/100\t|\tTrain loss: 0.12883811399739167\t|\tVal loss: 0.14708356486820254\n",
      "Epoch: 33/100\t|\tTrain loss: 0.1270277929253237\t|\tVal loss: 0.1501080891255638\n",
      "Epoch: 34/100\t|\tTrain loss: 0.12363442968539622\t|\tVal loss: 0.14445450993487158\n",
      "Epoch: 35/100\t|\tTrain loss: 0.12093482253999915\t|\tVal loss: 0.1480055742791773\n",
      "Epoch: 36/100\t|\tTrain loss: 0.12246886971469718\t|\tVal loss: 0.14187442752082138\n",
      "Epoch: 37/100\t|\tTrain loss: 0.12521351663219138\t|\tVal loss: 0.14410687732544167\n",
      "Epoch: 38/100\t|\tTrain loss: 0.11989222181810195\t|\tVal loss: 0.15670254979325057\n",
      "Epoch: 39/100\t|\tTrain loss: 0.11580559535339584\t|\tVal loss: 0.13637644516018968\n",
      "Epoch: 40/100\t|\tTrain loss: 0.10788047383511883\t|\tVal loss: 0.1348562587894112\n",
      "Epoch: 41/100\t|\tTrain loss: 0.10473871756372206\t|\tVal loss: 0.13378321157499762\n",
      "Epoch: 42/100\t|\tTrain loss: 0.10290918118291616\t|\tVal loss: 0.12776022444800822\n",
      "Epoch: 43/100\t|\tTrain loss: 0.10042564985072211\t|\tVal loss: 0.13020781392428768\n",
      "Epoch: 44/100\t|\tTrain loss: 0.10017669244477549\t|\tVal loss: 0.12527588987166632\n",
      "Epoch: 45/100\t|\tTrain loss: 0.09756043621931858\t|\tVal loss: 0.1289416182828665\n",
      "Epoch: 46/100\t|\tTrain loss: 0.09557573514142646\t|\tVal loss: 0.12374298709876076\n",
      "Epoch: 47/100\t|\tTrain loss: 0.09376618641455499\t|\tVal loss: 0.12429187863974082\n",
      "Epoch: 48/100\t|\tTrain loss: 0.09293094455766239\t|\tVal loss: 0.12873113474793882\n",
      "Epoch: 49/100\t|\tTrain loss: 0.0939248000324994\t|\tVal loss: 0.12242717217011198\n",
      "Epoch: 50/100\t|\tTrain loss: 0.09223083349597583\t|\tVal loss: 0.1235243232217422\n",
      "Epoch: 51/100\t|\tTrain loss: 0.10319733848874874\t|\tVal loss: 0.12508622306846984\n",
      "Epoch: 52/100\t|\tTrain loss: 0.09193233943888196\t|\tVal loss: 0.12465857812334147\n",
      "Epoch: 53/100\t|\tTrain loss: 0.08578028364825803\t|\tVal loss: 0.11747536246198255\n",
      "Epoch: 54/100\t|\tTrain loss: 0.08585745442106145\t|\tVal loss: 0.11611647036720495\n",
      "Epoch: 55/100\t|\tTrain loss: 0.08374943313560539\t|\tVal loss: 0.11942026583013617\n",
      "Epoch: 56/100\t|\tTrain loss: 0.09124272603693005\t|\tVal loss: 0.11962972505410932\n",
      "Epoch: 57/100\t|\tTrain loss: 0.08403480699303333\t|\tVal loss: 0.12455078621611525\n",
      "Epoch: 58/100\t|\tTrain loss: 0.09337598575552787\t|\tVal loss: 0.1316282722719115\n",
      "Epoch: 59/100\t|\tTrain loss: 0.08246318330317373\t|\tVal loss: 0.11659739435828703\n",
      "Epoch: 60/100\t|\tTrain loss: 0.07845196291343666\t|\tVal loss: 0.12438086732273865\n",
      "Epoch: 61/100\t|\tTrain loss: 0.08600296203607319\t|\tVal loss: 0.12134924858692588\n",
      "Epoch: 62/100\t|\tTrain loss: 0.07761001984312867\t|\tVal loss: 0.11232518896804183\n",
      "Epoch: 63/100\t|\tTrain loss: 0.07430421639364516\t|\tVal loss: 0.11167508287541103\n",
      "Epoch: 64/100\t|\tTrain loss: 0.07233521236690973\t|\tVal loss: 0.11447265015505657\n",
      "Epoch: 65/100\t|\tTrain loss: 0.07526543852188969\t|\tVal loss: 0.12186056435538782\n",
      "Epoch: 66/100\t|\tTrain loss: 0.07304936654557781\t|\tVal loss: 0.11161036515532351\n",
      "Epoch: 67/100\t|\tTrain loss: 0.07184190710785904\t|\tVal loss: 0.10902716353365897\n",
      "Epoch: 68/100\t|\tTrain loss: 0.06886954543288486\t|\tVal loss: 0.1060501139887375\n",
      "Epoch: 69/100\t|\tTrain loss: 0.06729118458127015\t|\tVal loss: 0.10826876583563748\n",
      "Epoch: 70/100\t|\tTrain loss: 0.06739621719228348\t|\tVal loss: 0.1075880983329442\n",
      "Epoch: 71/100\t|\tTrain loss: 0.06560018443764187\t|\tVal loss: 0.10550729303964147\n",
      "Epoch: 72/100\t|\tTrain loss: 0.0645042572474575\t|\tVal loss: 0.10611482674453152\n",
      "Epoch: 73/100\t|\tTrain loss: 0.06559787859577981\t|\tVal loss: 0.10810465267935737\n",
      "Epoch: 74/100\t|\tTrain loss: 0.06802594804772075\t|\tVal loss: 0.1118377233195815\n",
      "Epoch: 75/100\t|\tTrain loss: 0.0700947366212341\t|\tVal loss: 0.10963521934435015\n",
      "Epoch: 76/100\t|\tTrain loss: 0.0665282692272409\t|\tVal loss: 0.10916147228494953\n",
      "Epoch: 77/100\t|\tTrain loss: 0.06385784306204041\t|\tVal loss: 0.10542259728429913\n",
      "Epoch: 78/100\t|\tTrain loss: 0.06246681972204624\t|\tVal loss: 0.10467062605879776\n",
      "Epoch: 79/100\t|\tTrain loss: 0.05968954806455766\t|\tVal loss: 0.10959298805201441\n",
      "Epoch: 80/100\t|\tTrain loss: 0.062106195941551895\t|\tVal loss: 0.11427599071595165\n",
      "Epoch: 81/100\t|\tTrain loss: 0.05887697957153327\t|\tVal loss: 0.10248228522945557\n",
      "Epoch: 82/100\t|\tTrain loss: 0.0583628650950077\t|\tVal loss: 0.11148622394783957\n",
      "Epoch: 83/100\t|\tTrain loss: 0.06347268327511653\t|\tVal loss: 0.10892920762664843\n",
      "Epoch: 84/100\t|\tTrain loss: 0.06083317926440151\t|\tVal loss: 0.10613558957703613\n",
      "Epoch: 85/100\t|\tTrain loss: 0.06076438325499652\t|\tVal loss: 0.11027716032521001\n",
      "Epoch: 86/100\t|\tTrain loss: 0.058093153188194656\t|\tVal loss: 0.10497450602281488\n",
      "Epoch: 87/100\t|\tTrain loss: 0.05719955059731739\t|\tVal loss: 0.10485829591386747\n",
      "Epoch: 88/100\t|\tTrain loss: 0.058685108985636704\t|\tVal loss: 0.10780094729161455\n",
      "Epoch: 89/100\t|\tTrain loss: 0.053997791992495894\t|\tVal loss: 0.10613000967181964\n",
      "Epoch: 90/100\t|\tTrain loss: 0.05657259865032173\t|\tVal loss: 0.1036460717400434\n",
      "Epoch: 91/100\t|\tTrain loss: 0.05534891439482088\t|\tVal loss: 0.10987546171337804\n",
      "Epoch: 92/100\t|\tTrain loss: 0.05370775766776808\t|\tVal loss: 0.10741283786391245\n",
      "Epoch: 93/100\t|\tTrain loss: 0.05099316710045289\t|\tVal loss: 0.10289474738392773\n",
      "Epoch: 94/100\t|\tTrain loss: 0.05365079611581247\t|\tVal loss: 0.10969971491540925\n",
      "Epoch: 95/100\t|\tTrain loss: 0.053548411588524525\t|\tVal loss: 0.1025440303190081\n",
      "Epoch: 96/100\t|\tTrain loss: 0.050079393397192445\t|\tVal loss: 0.1010247914699688\n",
      "Epoch: 97/100\t|\tTrain loss: 0.050317079848187715\t|\tVal loss: 0.09959716648153213\n",
      "Epoch: 98/100\t|\tTrain loss: 0.05165945868725659\t|\tVal loss: 0.10559014634651818\n",
      "Epoch: 99/100\t|\tTrain loss: 0.0509861758198122\t|\tVal loss: 0.10263732472958913\n",
      "Epoch: 100/100\t|\tTrain loss: 0.0474468544508567\t|\tVal loss: 0.1062108422027889\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the model's accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data:  0.9535452322738386\n"
     ]
    }
   ],
   "source": [
    "# report model accuracy on test data\n",
    "model = MLP(input_dim=len(x_test[0]), output_dim=7, dropout=0.0).to(device)\n",
    "model.load_state_dict(torch.load('mlp.pth'))\n",
    "\n",
    "model.eval()\n",
    "# TODO\n",
    "predicted = []\n",
    "for x, y in test_loader:\n",
    "    temp = model(x)\n",
    "    for idx, i in enumerate(temp):\n",
    "        predicted.append((torch.argmax(i).item() == y[idx]).item())\n",
    "\n",
    "print('Accuracy on test data: ', sum(predicted)/len(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the sake of curiosity, let's take a random sample from the test set and see the model's prediction. So, randomly choose a sample from the test set and print it out (to see its features and also the correct output). Then, feed the features into your model and see what it predicts. Is it correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_long</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_long</th>\n",
       "      <th>dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "      <td>[restaurant, [35.765, 51.075]]</td>\n",
       "      <td>13:32:00</td>\n",
       "      <td>14:33:00</td>\n",
       "      <td>25.93</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.765</td>\n",
       "      <td>51.075</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  Day origin                     destination start_time  \\\n",
       "2488        3    1   work  [restaurant, [35.765, 51.075]]   13:32:00   \n",
       "\n",
       "      end_time  price  origin_lat  origin_long  dest_lat  dest_long  \\\n",
       "2488  14:33:00  25.93      35.625       51.375    35.765     51.075   \n",
       "\n",
       "            dest  \n",
       "2488  restaurant  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n",
      "After preprocessing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_long</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_long</th>\n",
       "      <th>dest</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>gym</th>\n",
       "      <th>home</th>\n",
       "      <th>park</th>\n",
       "      <th>pool</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>university</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>-0.875942</td>\n",
       "      <td>-0.202723</td>\n",
       "      <td>-0.124073</td>\n",
       "      <td>0.589929</td>\n",
       "      <td>-0.873639</td>\n",
       "      <td>0.980602</td>\n",
       "      <td>0.102763</td>\n",
       "      <td>-1.376699</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Day  start_time  end_time     price  origin_lat  origin_long  \\\n",
       "2488 -0.875942   -0.202723 -0.124073  0.589929   -0.873639     0.980602   \n",
       "\n",
       "      dest_lat  dest_long        dest    0  ...   57   58   59  gym  home  \\\n",
       "2488  0.102763  -1.376699  restaurant  0.0  ...  0.0  0.0  0.0  0.0   0.0   \n",
       "\n",
       "      park  pool  restaurant  university  work  \n",
       "2488   0.0   0.0         0.0         0.0   1.0  \n",
       "\n",
       "[1 rows x 76 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# TODO: choose a random sample from test data and print it out\n",
    "from IPython.display import display\n",
    "\n",
    "sample_index = random.randint(0, len(test_data_raw))\n",
    "print(\"Before preprocessing:\")\n",
    "display(test_data_raw.iloc[sample_index:sample_index+1])\n",
    "print('=============================================================')\n",
    "print(\"After preprocessing:\")\n",
    "display(test_data.iloc[sample_index:sample_index+1])\n",
    "print('=============================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted destination: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO: predict the destination of the above sample\n",
    "# print out the prediction\n",
    "predicted_dest = torch.argmax(model(x_test[sample_index].unsqueeze(0))).item()\n",
    "print(\"Predicted destination: \", end='')\n",
    "print(predicted_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual destination: 0\n"
     ]
    }
   ],
   "source": [
    "# TODO: print out the actual destination of the above sample\n",
    "print(\"Actual destination: \", end='')\n",
    "print(y_test[sample_index].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the inverse transform of the encoding you used earlier to get the name of the destination from the predicted class. Print it out and see if it's correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of predicted destination: restaurant\n",
      "Name of actual destination:    restaurant\n"
     ]
    }
   ],
   "source": [
    "# TODO: use inverse_transform to print out the actual name of destination of the above sample\n",
    "print('Name of predicted destination: ', end='')\n",
    "for k, v in dest_dict.items():\n",
    "    if v == predicted_dest:\n",
    "        print(k)\n",
    "        break\n",
    "print('Name of actual destination:    ', end='')\n",
    "for k, v in dest_dict.items():\n",
    "    if v == y_test[sample_index].item():\n",
    "        print(k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use Neural Networks for this problem? Why (or why not)? If the patterns in our datatset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "Your Answer: Using a MLP, can be a good approach for predicting passenger destinations, especially when dealing with complex patterns. Neural networks excel at capturing non-linear relationships and automatically learning relevant features. They are adaptable and expressive. However, considerations include the need for a sufficient amount of data, computational resources for training, hyperparameter tuning, and potential challenges in model interpretability. Overall, MLPs are often robust in handling intricate patterns, but careful consideration of specific dataset characteristics is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Submit:\n",
    "\n",
    "Please upload your notebook (`.ipynb`) compressed (as a `.zip` file) or uncompressed on Quera. **Note** that for each part, the accuracy of your model on the given test dataset is important. So, your accuracy should be **at least** same as ours (or better). Also, we will check your code after the submission. So, please make sure that there are no **data snooping** or **data leakage** in your code. You **can not** use the test data in any stages for your model, except for the final evaluation part! So, please be ware of that, or you may lose points.\n",
    "\n",
    "Your project is graded via 2 main parts: \n",
    "1. Checking out your implementation (to check if there are no \"data snooping\" and \"data leakage\") \n",
    "   \n",
    "2. Checking accuracies of your models on the test set. \n",
    "\n",
    "3. Running again your code by you in the \"in-person\" session and hearing your explanations (on the parts that we asked questions about the models, overfitting and etc. with tag \"QUESTION\" in the notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
